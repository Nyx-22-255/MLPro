<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>4.6 3rd Party Support &mdash; MLPro Documentations 1.0.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="4.7 Getting Started" href="07_getstarted.html" />
    <link rel="prev" title="4.5 Training" href="05_train.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MLPro Documentations
            <img src="../../_static/logo_mlpro.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">1 Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">1.1 What is MLPro?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/getstarted.html">1.2 Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/architecture.html">1.3 Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">2 MLPro-BF – Basic Functions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../bf/01_overview.html">2.1 Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bf/02_elementary.html">2.2 Elementary Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bf/03_math.html">2.3 Mathematics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bf/04_ml.html">2.4 Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bf/05_ui.html">2.5 User Interaction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">3 MLPro-SL - Supervised Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../sl/01_overview.html">3.1 Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sl/02_adaptive_function.html">3.2 Adaptive Function</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">4 MLPro-RL - Reinforcement Learning</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="01_overview.html">4.1 Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_env.html">4.2 Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_agents.html">4.3 Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_scenario.html">4.4 RL-Scenarios</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_train.html">4.5 Training</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">4.6 3rd Party Support</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#rl-environment-openai-gym-to-mlpro">RL Environment: OpenAI Gym to MLPro</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rl-environment-mlpro-to-openai-gym">RL Environment: MLPro to OpenAI Gym</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rl-environment-pettingzoo-to-mlpro">RL Environment: PettingZoo to MLPro</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rl-environment-mlpro-to-pettingzoo">RL Environment: MLPro to PettingZoo</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rl-policy-stablebaselines3-to-mlpro">RL Policy: StableBaselines3 to MLPro</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="07_getstarted.html">4.7 Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">5 MLPro-GT – Game Theory</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gt/01_overview.html">5.1 Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gt/02_players.html">5.2 Players</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gt/03_gameboard.html">5.3 Game Boards</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gt/04_getstarted.html">5.4 Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">6 MLPro-OA – Online Adaptivity</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../oa/01_overview.html">6.1 Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oa/02_getstarted.html">6.2 Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Appendix 1: Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../append1/howto.bf.html">Basic Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../append1/howto.rl.html">Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../append1/howto.gt.html">Game Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../append1/howto.oa.html">Online Adaptivity</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Appendix 2: API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../append2/mlpro.core.html">Core Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../append2/mlpro.wrappers.html">Wrappers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../append2/mlpro.pool.html">Pool Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../append2/mlpro.template.html">Templates</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Appendix 3: Project MLPro</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../append3/versions.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../append3/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../append3/cont.html">Contribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../append3/disclaimer.html">Disclaimer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MLPro Documentations</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>4.6 3rd Party Support</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/fhswf/MLPro/blob/main/doc/docs/content/rl/06_wrapper.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="rd-party-support">
<span id="target-package"></span><h1>4.6 3rd Party Support<a class="headerlink" href="#rd-party-support" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://github.com/fhswf/MLPro.git">MLPro</a> allows the user to reuse widely-used 3rd-party packages and
integrate them to the MLPro interface and also the other way around via wrapper classes.
Therefore, the user is free to select an environment and/or a policy from the 3rd-party packages and the native MLPro-RL.
It is also possible to combine an environment and a policy from different packages.</p>
<p>At the moment, we have five ready-to-use wrapper classes related to RL from 3rd-party packages to MLPro and two wrapper classes from MLPro to 3rd-party packages, such as:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 6%" />
<col style="width: 18%" />
<col style="width: 20%" />
<col style="width: 19%" />
<col style="width: 38%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>No</p></th>
<th class="head"><p>Wrapper Class</p></th>
<th class="head"><p>Origin</p></th>
<th class="head"><p>Target</p></th>
<th class="head"><p>Wrapped RL Components</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>WrEnvGYM2MLPro</p></td>
<td><p>OpenAI Gym</p></td>
<td><p>MLPro</p></td>
<td><p>RL Environments</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>WrEnvMLPro2GYM</p></td>
<td><p>MLPro</p></td>
<td><p>OpenAI Gym</p></td>
<td><p>RL Environments</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>WrEnvPZOO2MLPro</p></td>
<td><p>PettingZoo</p></td>
<td><p>MLPro</p></td>
<td><p>Multi-Agent RL Environments</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>WrEnvMLPro2PZoo</p></td>
<td><p>MLPro</p></td>
<td><p>PettingZoo</p></td>
<td><p>Multi-Agent RL Environments</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>WrPolicySB32MLPro</p></td>
<td><p>StableBaselines3</p></td>
<td><p>MLPro</p></td>
<td><p>Off-Policy and On-Policy RL Algorithms</p></td>
</tr>
</tbody>
</table>
<p>Moreover, wrapper classes for hyperparameter tuning by <a class="reference external" href="https://mlpro.readthedocs.io/en/latest/content/append1/bf/howto.bf.008.html">Optuna</a> and <a class="reference external" href="https://mlpro.readthedocs.io/en/latest/content/append1/bf/howto.bf.007.html">Hyperopt</a> can also be incorporated to your RL training.</p>
<section id="rl-environment-openai-gym-to-mlpro">
<h2>RL Environment: OpenAI Gym to MLPro<a class="headerlink" href="#rl-environment-openai-gym-to-mlpro" title="Permalink to this headline"></a></h2>
<p>Here is the wrapper class to convert RL Environment from OpenAI Gym to MLPro.
The implementation is pretty simple and straightforward.
The user can call the wrapper class while setting up an environment, as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlpro.wrappers.openai_gym</span> <span class="kn">import</span> <span class="n">WrEnvGYM2MLPro</span>
<span class="kn">import</span> <span class="nn">gym</span>

<span class="n">p_gym_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">,</span> <span class="n">new_step_api</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">_env</span> <span class="o">=</span> <span class="n">WrEnvGYM2MLPro</span><span class="p">(</span><span class="n">p_gym_env</span><span class="p">,</span> <span class="n">p_logging</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>For more information, please check the <a class="reference external" href="https://mlpro.readthedocs.io/en/latest/content/append1/rl/howto.rl.002.html">how-to file</a>.</p>
</section>
<section id="rl-environment-mlpro-to-openai-gym">
<h2>RL Environment: MLPro to OpenAI Gym<a class="headerlink" href="#rl-environment-mlpro-to-openai-gym" title="Permalink to this headline"></a></h2>
<p>Here is the wrapper class to convert RL Environment from MLPro to OpenAI Gym.
The implementation is pretty simple and straightforward.
The user can call the wrapper class while setting up an environment, as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlpro.wrappers.openai_gym</span> <span class="kn">import</span> <span class="n">WrEnvMLPro2GYM</span>
<span class="kn">from</span> <span class="nn">mlpro.rl.pool.envs.gridworld</span> <span class="kn">import</span> <span class="n">GridWorld</span>

<span class="n">mlpro_env</span> <span class="o">=</span> <span class="n">GridWorld</span><span class="p">(</span><span class="n">p_logging</span><span class="o">=</span><span class="n">Log</span><span class="o">.</span><span class="n">C_LOG_ALL</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">WrEnvMLPro2GYM</span><span class="p">(</span><span class="n">mlpro_env</span><span class="p">,</span> <span class="n">p_state_space</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">p_action_space</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">p_new_step_api</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>For more information, please check the <a class="reference external" href="https://mlpro.readthedocs.io/en/latest/content/append1/rl/howto.rl.008.html">how-to file</a>.</p>
</section>
<section id="rl-environment-pettingzoo-to-mlpro">
<h2>RL Environment: PettingZoo to MLPro<a class="headerlink" href="#rl-environment-pettingzoo-to-mlpro" title="Permalink to this headline"></a></h2>
<p>Here is the wrapper class to convert RL Environment from PettingZoo to MLPro.
The implementation is pretty simple and straightforward.
The user can call the wrapper class while setting up an environment, as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pettingzoo.butterfly</span> <span class="kn">import</span> <span class="n">pistonball_v6</span>
<span class="kn">from</span> <span class="nn">mlpro.wrappers.pettingzoo</span> <span class="kn">import</span> <span class="n">WrEnvPZOO2MLPro</span>

<span class="n">p_zoo_env</span> <span class="o">=</span> <span class="n">pistonball_v6</span><span class="o">.</span><span class="n">env</span><span class="p">()</span>
<span class="bp">self</span><span class="o">.</span><span class="n">_env</span> <span class="o">=</span> <span class="n">WrEnvPZOO2MLPro</span><span class="p">(</span><span class="n">p_zoo_env</span><span class="p">,</span> <span class="n">p_logging</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>For more information, please check the <a class="reference external" href="https://mlpro.readthedocs.io/en/latest/content/append1/rl/howto.rl.006.html">how-to file</a>.</p>
</section>
<section id="rl-environment-mlpro-to-pettingzoo">
<h2>RL Environment: MLPro to PettingZoo<a class="headerlink" href="#rl-environment-mlpro-to-pettingzoo" title="Permalink to this headline"></a></h2>
<p>Here is the wrapper class to convert RL Environment from MLPro to PettingZoo.
The implementation is pretty simple and straightforward.
The user can call the wrapper class while setting up an environment, as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlpro.wrappers.pettingzoo</span> <span class="kn">import</span> <span class="n">WrEnvMLPro2PZoo</span>
<span class="kn">from</span> <span class="nn">mlpro.rl.pool.envs.bglp</span> <span class="kn">import</span> <span class="n">BGLP</span>

<span class="n">mlpro_env</span> <span class="o">=</span> <span class="n">BGLP</span><span class="p">(</span><span class="n">p_logging</span><span class="o">=</span><span class="n">Mode</span><span class="o">.</span><span class="n">C_LOG_ALL</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">WrEnvMLPro2PZoo</span><span class="p">(</span><span class="n">mlpro_env</span><span class="p">,</span> <span class="n">p_num_agents</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">p_state_space</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">p_action_space</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">pzoo_env</span>
</pre></div>
</div>
<p>For more information, please check the <a class="reference external" href="https://mlpro.readthedocs.io/en/latest/content/append1/rl/howto.rl.009.html">how-to file</a>.</p>
</section>
<section id="rl-policy-stablebaselines3-to-mlpro">
<h2>RL Policy: StableBaselines3 to MLPro<a class="headerlink" href="#rl-policy-stablebaselines3-to-mlpro" title="Permalink to this headline"></a></h2>
<p>Here is the wrapper class to convert RL Environment from StableBaselines3 to MLPro.
The wrapper provides both the On-Policy and Off-Policy from StableBaselines3.
The implementation is pretty simple and straightforward.
The user can call the wrapper class while setting up an environment, as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">mlpro.rl.wrappers</span> <span class="kn">import</span> <span class="n">WrPolicySB32MLPro</span>

<span class="k">class</span> <span class="nc">MyScenario</span><span class="p">(</span><span class="n">Scenario</span><span class="p">):</span>

    <span class="n">C_NAME</span>      <span class="o">=</span> <span class="s1">&#39;Matrix&#39;</span>

    <span class="k">def</span> <span class="nf">_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_mode</span><span class="p">,</span> <span class="n">p_ada</span><span class="p">,</span> <span class="n">p_logging</span><span class="p">):</span>
        <span class="n">gym_env</span>     <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_env</span>   <span class="o">=</span> <span class="n">WrEnvGYM2MLPro</span><span class="p">(</span><span class="n">gym_env</span><span class="p">,</span> <span class="n">p_logging</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">policy_sb3</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span>
            <span class="n">policy</span><span class="o">=</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span>
            <span class="n">n_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">env</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">_init_setup_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="n">policy_wrapped</span> <span class="o">=</span> <span class="n">WrPolicySB32MLPro</span><span class="p">(</span>
            <span class="n">p_sb3_policy</span><span class="o">=</span><span class="n">policy_sb3</span><span class="p">,</span>
            <span class="n">p_cycle_limit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cycle_limit</span><span class="p">,</span>
            <span class="n">p_observation_space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_env</span><span class="o">.</span><span class="n">get_state_space</span><span class="p">(),</span>
            <span class="n">p_action_space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_env</span><span class="o">.</span><span class="n">get_action_space</span><span class="p">(),</span>
            <span class="n">p_ada</span><span class="o">=</span><span class="n">p_ada</span><span class="p">,</span>
            <span class="n">p_logging</span><span class="o">=</span><span class="n">p_logging</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">Agent</span><span class="p">(</span>
            <span class="n">p_policy</span><span class="o">=</span><span class="n">policy_wrapped</span><span class="p">,</span>
            <span class="n">p_envmodel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">p_name</span><span class="o">=</span><span class="s1">&#39;Smith&#39;</span><span class="p">,</span>
            <span class="n">p_ada</span><span class="o">=</span><span class="n">p_ada</span><span class="p">,</span>
            <span class="n">p_logging</span><span class="o">=</span><span class="n">p_logging</span>
        <span class="p">)</span>
</pre></div>
</div>
<p>For more information, please check the <a class="reference external" href="https://mlpro.readthedocs.io/en/latest/content/append1/rl/howto.rl.007.html">how-to file</a>.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="05_train.html" class="btn btn-neutral float-left" title="4.5 Training" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="07_getstarted.html" class="btn btn-neutral float-right" title="4.7 Getting Started" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021 South Westphalia University of Applied Sciences, Germany.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>