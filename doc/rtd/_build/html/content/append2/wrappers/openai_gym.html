<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>OpenAI Gym &mdash; MLPro Documentations 1.0.0 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="OpenML" href="openml.html" />
    <link rel="prev" title="Hyperopt" href="hyperopt.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> MLPro Documentations
            <img src="../../../_static/logo_mlpro.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">1 Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro/overview.html">1.1 What is MLPro?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro/getstarted.html">1.2 Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro/architecture.html">1.3 Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">2 MLPro-BF – Basic Functions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../bf/01_overview.html">2.1 Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bf/02_elementary.html">2.2 Elementary Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bf/03_math.html">2.3 Mathematics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bf/04_ml.html">2.4 Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bf/05_ui.html">2.5 User Interaction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">3 MLPro-SL - Supervised Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../sl/01_overview.html">3.1 Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sl/02_adaptive_function.html">3.2 Adaptive Function</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">4 MLPro-RL - Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../rl/01_overview.html">4.1 Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rl/02_env.html">4.2 Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rl/03_agents.html">4.3 Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rl/04_scenario.html">4.4 RL-Scenarios</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rl/05_train.html">4.5 Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rl/06_wrapper.html">4.6 3rd Party Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rl/07_getstarted.html">4.7 Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">5 MLPro-GT – Game Theory</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../gt/01_overview.html">5.1 Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gt/02_players.html">5.2 Players</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gt/03_gameboard.html">5.3 Game Boards</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gt/04_getstarted.html">5.4 Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">6 MLPro-OA – Online Adaptivity</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../oa/01_overview.html">6.1 Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../oa/02_getstarted.html">6.2 Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Appendix 1: Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../append1/howto.bf.html">Basic Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../append1/howto.rl.html">Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../append1/howto.gt.html">Game Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../append1/howto.oa.html">Online Adaptivity</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Appendix 2: API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mlpro.core.html">Core Functions</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../mlpro.wrappers.html">Wrappers</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="hyperopt.html">Hyperopt</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">OpenAI Gym</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cross-references">Cross References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="openml.html">OpenML</a></li>
<li class="toctree-l2"><a class="reference internal" href="optuna.html">Optuna</a></li>
<li class="toctree-l2"><a class="reference internal" href="pettingzoo.html">PettingZoo</a></li>
<li class="toctree-l2"><a class="reference internal" href="river.html">River</a></li>
<li class="toctree-l2"><a class="reference internal" href="sb3.html">Stable Baslines3</a></li>
<li class="toctree-l2"><a class="reference internal" href="sklearn.html">Scikit-learn</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mlpro.pool.html">Pool Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mlpro.template.html">Templates</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Appendix 3: Project MLPro</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../append3/versions.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../append3/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../append3/cont.html">Contribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../append3/disclaimer.html">Disclaimer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MLPro Documentations</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../mlpro.wrappers.html">Wrappers</a> &raquo;</li>
      <li>OpenAI Gym</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/fhswf/MLPro/blob/main/doc/docs/content/append2/wrappers/openai_gym.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-mlpro.wrappers.openai_gym">
<span id="openai-gym"></span><h1>OpenAI Gym<a class="headerlink" href="#module-mlpro.wrappers.openai_gym" title="Permalink to this headline"></a></h1>
<p>Ver. 1.4.3 (2022-08-15)</p>
<p>This module provides wrapper classes for OpenAI Gym environments.</p>
<p>See also: <a class="reference external" href="https://pypi.org/project/gym">https://pypi.org/project/gym</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlpro.wrappers.openai_gym.</span></span><span class="sig-name descname"><span class="pre">WrEnvGYM2MLPro</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p_gym_env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_state_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.MSpace" title="mlpro.bf.math.MSpace"><span class="pre">mlpro.bf.math.MSpace</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_action_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.MSpace" title="mlpro.bf.math.MSpace"><span class="pre">mlpro.bf.math.MSpace</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_logging</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.wrappers.models.Wrapper</span></code>, <a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_env.Environment" title="mlpro.rl.models_env.Environment"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_env.Environment</span></code></a></p>
<p>This class is a ready to use wrapper class for OpenAI Gym environments.
Objects of this type can be treated as an environment object. Encapsulated
gym environment must be compatible to class gym.Env.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_gym_env</strong> (<em>Env</em>) – Gym environment object</p></li>
<li><p><strong>p_state_space</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.MSpace" title="mlpro.bf.math.MSpace"><em>MSpace</em></a>) – Optional external state space object that meets the state space of the Gym environment</p></li>
<li><p><strong>p_action_space</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.MSpace" title="mlpro.bf.math.MSpace"><em>MSpace</em></a>) – Optional external action space object that meets the action space of the Gym environment</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class Log). Default = Log.C_LOG_ALL.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.C_TYPE">
<span class="sig-name descname"><span class="pre">C_TYPE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Wrapper</span> <span class="pre">OpenAI</span> <span class="pre">Gym</span> <span class="pre">-&gt;</span> <span class="pre">MLPro'</span></em><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.C_TYPE" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.C_WRAPPED_PACKAGE">
<span class="sig-name descname"><span class="pre">C_WRAPPED_PACKAGE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'gym'</span></em><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.C_WRAPPED_PACKAGE" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.recognize_space">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">recognize_space</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p_gym_space</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.ESpace" title="mlpro.bf.math.ESpace"><span class="pre">mlpro.bf.math.ESpace</span></a></span></span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.recognize_space" title="Permalink to this definition"></a></dt>
<dd><p>Detecting a gym space and transform it to MLPro space. Hence, the transformed space can be
directly compatible in MLPro.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_gym_space</strong> (container spaces (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>)) – Spaces are crucially used in Gym to define the format of valid actions and observations.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>space</strong> – MLPro compatible space.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.ESpace" title="mlpro.bf.math.ESpace">ESpace</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.setup_spaces">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">setup_spaces</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.setup_spaces" title="Permalink to this definition"></a></dt>
<dd><p>To setup spaces. To be optionally defined by the users.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.simulate_reaction">
<span class="sig-name descname"><span class="pre">simulate_reaction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State"><span class="pre">mlpro.rl.models_sar.State</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_action</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.Action" title="mlpro.rl.models_sar.Action"><span class="pre">mlpro.rl.models_sar.Action</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State"><span class="pre">mlpro.rl.models_sar.State</span></a></span></span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.simulate_reaction" title="Permalink to this definition"></a></dt>
<dd><p>Simulates a state transition based on a state and an action. The simulation step itself is
carried out either by an internal custom implementation in method _simulate_reaction() or
by an embedded adaptive function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_state</strong> (<a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State"><em>State</em></a>) – Current state.</p></li>
<li><p><strong>p_action</strong> (<a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.Action" title="mlpro.rl.models_sar.Action"><em>Action</em></a>) – Action.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>state</strong> – Subsequent state after transition</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State">State</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_reward">
<span class="sig-name descname"><span class="pre">compute_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p_state_old</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State"><span class="pre">mlpro.rl.models_sar.State</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_state_new</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State"><span class="pre">mlpro.rl.models_sar.State</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.Reward" title="mlpro.rl.models_sar.Reward"><span class="pre">mlpro.rl.models_sar.Reward</span></a></span></span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_reward" title="Permalink to this definition"></a></dt>
<dd><p>Computes a reward for the state transition, given by two successive states. The reward
computation itself is carried out either by a custom implementation in method
_compute_reward() or by an embedded adaptive function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_state_old</strong> (<a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State"><em>State</em></a>) – Optional state before transition. If None the internal previous state of the environment
is used.</p></li>
<li><p><strong>p_state_new</strong> (<a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State"><em>State</em></a>) – Optional tate after transition. If None the internal current state of the environment
is used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Reward object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.Reward" title="mlpro.rl.models_sar.Reward">Reward</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_success">
<span class="sig-name descname"><span class="pre">compute_success</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State"><span class="pre">mlpro.rl.models_sar.State</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_success" title="Permalink to this definition"></a></dt>
<dd><p>Assesses the given state whether it is a ‘success’ state. Assessment is carried out either by
a custom implementation in method _compute_success() or by an embedded adaptive function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_state</strong> (<a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State"><em>State</em></a>) – State to be assessed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True, if the given state is a ‘success’ state. False otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_broken">
<span class="sig-name descname"><span class="pre">compute_broken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State"><span class="pre">mlpro.rl.models_sar.State</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_broken" title="Permalink to this definition"></a></dt>
<dd><p>Assesses the given state whether it is a ‘broken’ state. Assessment is carried out either by
a custom implementation in method _compute_broken() or by an embedded adaptive function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_state</strong> (<a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_sar.State" title="mlpro.rl.models_sar.State"><em>State</em></a>) – State to be assessed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True, if the given state is a ‘broken’ state. False otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.init_plot">
<span class="sig-name descname"><span class="pre">init_plot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p_figure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.init_plot" title="Permalink to this definition"></a></dt>
<dd><p>Plot initialization function, deployed by render functionality from OpenAI Gym.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.update_plot">
<span class="sig-name descname"><span class="pre">update_plot</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.update_plot" title="Permalink to this definition"></a></dt>
<dd><p>Updating the actual plot, deployed by render functionality from OpenAI Gym.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.get_cycle_limit">
<span class="sig-name descname"><span class="pre">get_cycle_limit</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.get_cycle_limit" title="Permalink to this definition"></a></dt>
<dd><p>To obtain the information regarding the cycle limit from the environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the number of the cycle limit.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlpro.wrappers.openai_gym.</span></span><span class="sig-name descname"><span class="pre">WrEnvMLPro2GYM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p_mlpro_env</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_env.Environment" title="mlpro.rl.models_env.Environment"><span class="pre">mlpro.rl.models_env.Environment</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_state_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.MSpace" title="mlpro.bf.math.MSpace"><span class="pre">mlpro.bf.math.MSpace</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_action_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.MSpace" title="mlpro.bf.math.MSpace"><span class="pre">mlpro.bf.math.MSpace</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_new_step_api</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_render_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_logging</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.wrappers.models.Wrapper</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">gym.core.Env</span></code></p>
<p>This class is a ready to use wrapper class for MLPro to OpenAI Gym environments.
Objects of this type can be treated as an gym.Env object. Encapsulated
MLPro environment must be compatible to class Environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_mlpro_env</strong> (<a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_env.Environment" title="mlpro.rl.models_env.Environment"><em>Environment</em></a>) – MLPro’s Environment object</p></li>
<li><p><strong>p_state_space</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.MSpace" title="mlpro.bf.math.MSpace"><em>MSpace</em></a>) – Optional external state space object that meets the state space of the MLPro environment</p></li>
<li><p><strong>p_action_space</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.MSpace" title="mlpro.bf.math.MSpace"><em>MSpace</em></a>) – Optional external action space object that meets the state space of the MLPro environment</p></li>
<li><p><strong>p_new_step_api</strong> (<em>bool</em>) – If true, the user assures that the environment compatible to Gym version 0.25.0 or above.
Otherwise, it is false. Default = False.</p></li>
<li><p><strong>p_render_mde</strong> (<em>str</em>) – To allow the user to specify render_mode handled by the environment, for instance,
‘human’, ‘rgb_array’, and ‘single_rgb_array’. Default = None.</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class Log). Default = Log.C_LOG_ALL.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.C_TYPE">
<span class="sig-name descname"><span class="pre">C_TYPE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Wrapper</span> <span class="pre">MLPro</span> <span class="pre">-&gt;</span> <span class="pre">OpenAI</span> <span class="pre">Gym'</span></em><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.C_TYPE" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.C_WRAPPED_PACKAGE">
<span class="sig-name descname"><span class="pre">C_WRAPPED_PACKAGE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'gym'</span></em><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.C_WRAPPED_PACKAGE" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.metadata">
<span class="sig-name descname"><span class="pre">metadata</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{'render.modes':</span> <span class="pre">['human']}</span></em><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.metadata" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.recognize_space">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">recognize_space</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p_mlpro_space</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.recognize_space" title="Permalink to this definition"></a></dt>
<dd><p>Detecting a MLPro space and transform it to gym space. Hence, the transformed space can be
directly compatible in gym.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_mlpro_space</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.ESpace" title="mlpro.bf.math.ESpace"><em>ESpace</em></a>) – MLPro compatible space.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>space</strong> – Spaces are crucially used in Gym to define the format of valid actions and observations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>container spaces (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.step" title="Permalink to this definition"></a></dt>
<dd><p>To execute one time step within the environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>action</strong> (<em>ActType</em>) – an action provided by the agent.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>obs</strong> (<em>object</em>) – This will be an element of the environment’s <code class="xref py py-attr docutils literal notranslate"><span class="pre">observation_space</span></code>.
This may, for instance, be a numpy array containing the positions and velocities of certain objects.</p></li>
<li><p><strong>reward.get_overall_reward()</strong> (<em>float</em>) – The amount of reward returned as a result of taking the action.</p></li>
<li><p><strong>terminated</strong> (<em>bool</em>) – whether a <cite>terminal state</cite> (as defined under the MDP of the task) is reached.
In this case further step() calls could return undefined results.</p></li>
<li><p><strong>truncated</strong> (<em>bool</em>) – whether a truncation condition outside the scope of the MDP is satisfied.
Typically a timelimit, but could also be used to indicate agent physically going out of bounds.
Can be used to end the episode prematurely before a <cite>terminal state</cite> is reached.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – It contains auxiliary diagnostic information (helpful for debugging, learning, and logging).
This might, for instance, contain: metrics that describe the agent’s performance state, variables that are
hidden from observations, or individual reward terms that are combined to produce the total reward.
It also can contain information that distinguishes truncation and termination, however this is deprecated in favour
of returning two booleans, and will be removed in a future version.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.reset" title="Permalink to this definition"></a></dt>
<dd><p>Resets the environment to an initial state and returns the initial observation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed</strong> (<em>int</em><em>, </em><em>optional</em>) – The seed that is used to initialize the environment’s PRNG.
If the environment does not already have a PRNG and <code class="docutils literal notranslate"><span class="pre">seed=None</span></code> (the default option) is passed,
a seed will be chosen from some source of entropy (e.g. timestamp or /dev/urandom).
However, if the environment already has a PRNG and <code class="docutils literal notranslate"><span class="pre">seed=None</span></code> is passed, the PRNG will <em>not</em> be reset.
If you pass an integer, the PRNG will be reset even if it already exists.
Usually, you want to pass an integer <em>right after the environment has been initialized and then never again</em>.
Please refer to the minimal example above to see this paradigm in action.
The default is None.</p></li>
<li><p><strong>return_info</strong> (<em>bool</em>) – If true, return additional information along with initial observation.
This info should be analogous to the info returned in <a class="reference internal" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.step" title="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code></a>.
The default is False.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>, </em><em>optional</em>) – Additional information to specify how the environment is reset (optional,
depending on the specific environment). The default is None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>obs</strong> (<em>object</em>) – This will be an element of the environment’s <code class="xref py py-attr docutils literal notranslate"><span class="pre">observation_space</span></code>.
This may, for instance, be a numpy array containing the positions and velocities of certain objects.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – It contains auxiliary diagnostic information (helpful for debugging, learning, and logging).
This might, for instance, contain: metrics that describe the agent’s performance state, variables that are
hidden from observations, or individual reward terms that are combined to produce the total reward.
It also can contain information that distinguishes truncation and termination, however this is deprecated in favour
of returning two booleans, and will be removed in a future version.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.render">
<span class="sig-name descname"><span class="pre">render</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">gym.core.RenderFrame</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">gym.core.RenderFrame</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.render" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.close" title="Permalink to this definition"></a></dt>
<dd><p>Override close in your subclass to perform any necessary cleanup.
Environments will automatically <a class="reference internal" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.close" title="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.close"><code class="xref py py-meth docutils literal notranslate"><span class="pre">close()</span></code></a> themselves when garbage collected or when the program exits.</p>
</dd></dl>

</dd></dl>

<section id="cross-references">
<h2>Cross References<a class="headerlink" href="#cross-references" title="Permalink to this headline"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference internal" href="../../append1/rl/howto.rl.002.html#howto-rl-002"><span class="std std-ref">Howto RL-002: Run an agent with an own policy with an OpenAI GYM environment</span></a></p></li>
<li><p><a class="reference internal" href="../../append1/rl/howto.rl.003.html#howto-rl-003"><span class="std std-ref">Howto RL-003: Train an agent with an own policy on an OpenAI Gym environment</span></a></p></li>
<li><p><a class="reference internal" href="../../append1/rl/howto.rl.004.html#howto-rl-004"><span class="std std-ref">Howto RL-004: Run a multi-agent with an own policy with an OpenAI Gym environment</span></a></p></li>
<li><p><a class="reference internal" href="../../append1/rl/howto.rl.008.html#howto-rl-008"><span class="std std-ref">Howto RL-008: Wrap native MLPro environment class to OpenAI Gym environment</span></a></p></li>
</ul>
</div></blockquote>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="hyperopt.html" class="btn btn-neutral float-left" title="Hyperopt" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="openml.html" class="btn btn-neutral float-right" title="OpenML" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021 South Westphalia University of Applied Sciences, Germany.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>