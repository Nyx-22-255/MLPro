<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Reinforcement Learning &mdash; MLPro Documentations 1.0.0 documentation</title><link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/custom.css" type="text/css" /><link rel="shortcut icon" href="../../../../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script src="../../../../../_static/language_data.js"></script>
        <script src="../../../../../_static/clipboard.min.js"></script>
        <script src="../../../../../_static/copybutton.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
    <link rel="next" title="Game Theory" href="mlpro.gt.html" />
    <link rel="prev" title="Supervised Learning" href="mlpro.sl.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../index.html" class="icon icon-home"> MLPro Documentations<img src="../../../../../_static/logo_mlpro.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Welcome to MLPro</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_welcome/sub/01_introduction.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_welcome/sub/02_getting_started.html">2. Getting Started</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic Functions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_basic_functions/mlpro_bf/main.html">7. MLPro-BF - Basic Functions</a></li>
</ul>
<p class="caption"><span class="caption-text">Machine Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_machine_learning/mlpro_sl/main.html">8. MLPro-SL - Supervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_machine_learning/mlpro_rl/main.html">9. MLPro-RL - Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_machine_learning/mlpro_gt/main.html">10. MLPro-GT - Game Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_machine_learning/mlpro_oa/main.html">11. MLPro-OA - Online Adaptivity</a></li>
</ul>
<p class="caption"><span class="caption-text">Appendices</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../appendix1/main.html">A1 - Example Pool</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../main.html">A2 - API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../01_mlpro.core.html">Core Functions</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="mlpro.bf.html">Basic Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="mlpro.sl.html">Supervised Learning</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Reinforcement Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#environments">Environments</a></li>
<li class="toctree-l4"><a class="reference internal" href="#adaptive-environments">Adaptive Environments</a></li>
<li class="toctree-l4"><a class="reference internal" href="#agents">Agents</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scenarios-training-and-tuning">Scenarios, Training and Tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mlpro.gt.html">Game Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="mlpro.oa.html">Online Adaptivity</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../02_mlpro.pool.html">Pool Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_mlpro.wrappers.html">Wrappers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../appendix3/main.html">A3 - Project MLPro</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">MLPro Documentations</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../main.html">A2 - API Reference</a> &raquo;</li>
          <li><a href="../01_mlpro.core.html">Core Functions</a> &raquo;</li>
      <li>Reinforcement Learning</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/fhswf/MLPro/blob/main/doc/docs/content/04_appendices/appendix2/sub/core/mlpro.rl.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="reinforcement-learning">
<h1>Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="Permalink to this headline">¶</a></h1>
<div class="section" id="environments">
<h2>Environments<a class="headerlink" href="#environments" title="Permalink to this headline">¶</a></h2>
<img alt="../../../../../_images/MLPro-RL-Env_class_diagram.drawio.png" src="../../../../../_images/MLPro-RL-Env_class_diagram.drawio.png" />
<span class="target" id="module-mlpro.rl.models_env"></span><p>Ver. 1.7.1 (2023-02-02)</p>
<p>This module provides model classes for environments.</p>
<dl class="py class">
<dt id="mlpro.rl.models_env.Reward">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env.</code><code class="sig-name descname">Reward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_type</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_value</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.Reward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="mlpro.bf.html#mlpro.bf.various.TStamp" title="mlpro.bf.various.TStamp"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.various.TStamp</span></code></a></p>
<p>Objects of this class represent rewards of environments. The internal structure
depends on the reward type. Three types are supported as listed below.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_type</strong> – Reward type (default: C_TYPE_OVERALL)</p></li>
<li><p><strong>p_value</strong> – Overall reward value (reward type C_TYPE_OVERALL only)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_env.Reward.C_TYPE_OVERALL">
<code class="sig-name descname">C_TYPE_OVERALL</code><em class="property"> = 0</em><a class="headerlink" href="#mlpro.rl.models_env.Reward.C_TYPE_OVERALL" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.Reward.C_TYPE_EVERY_AGENT">
<code class="sig-name descname">C_TYPE_EVERY_AGENT</code><em class="property"> = 1</em><a class="headerlink" href="#mlpro.rl.models_env.Reward.C_TYPE_EVERY_AGENT" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.Reward.C_TYPE_EVERY_ACTION">
<code class="sig-name descname">C_TYPE_EVERY_ACTION</code><em class="property"> = 2</em><a class="headerlink" href="#mlpro.rl.models_env.Reward.C_TYPE_EVERY_ACTION" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.Reward.C_VALID_TYPES">
<code class="sig-name descname">C_VALID_TYPES</code><em class="property"> = [0, 1, 2]</em><a class="headerlink" href="#mlpro.rl.models_env.Reward.C_VALID_TYPES" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.Reward.get_type">
<code class="sig-name descname">get_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.Reward.get_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.Reward.is_rewarded">
<code class="sig-name descname">is_rewarded</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_agent_id</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.rl.models_env.Reward.is_rewarded" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.Reward.set_overall_reward">
<code class="sig-name descname">set_overall_reward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_reward</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.rl.models_env.Reward.set_overall_reward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.Reward.get_overall_reward">
<code class="sig-name descname">get_overall_reward</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.Reward.get_overall_reward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.Reward.add_agent_reward">
<code class="sig-name descname">add_agent_reward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_agent_id</span></em>, <em class="sig-param"><span class="n">p_reward</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.rl.models_env.Reward.add_agent_reward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.Reward.get_agent_reward">
<code class="sig-name descname">get_agent_reward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_agent_id</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.Reward.get_agent_reward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.Reward.add_action_reward">
<code class="sig-name descname">add_action_reward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_agent_id</span></em>, <em class="sig-param"><span class="n">p_action_id</span></em>, <em class="sig-param"><span class="n">p_reward</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.rl.models_env.Reward.add_action_reward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.Reward.get_action_reward">
<code class="sig-name descname">get_action_reward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_agent_id</span></em>, <em class="sig-param"><span class="n">p_action_id</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.Reward.get_action_reward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_env.FctReward">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env.</code><code class="sig-name descname">FctReward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.FctReward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="mlpro.bf.html#mlpro.bf.various.Log" title="mlpro.bf.various.Log"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.various.Log</span></code></a></p>
<p>Template class for reward functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_logging</strong> – Log level (see class Log for more details).</p>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_env.FctReward.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'Fct Reward'</em><a class="headerlink" href="#mlpro.rl.models_env.FctReward.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.FctReward.compute_reward">
<code class="sig-name descname">compute_reward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_state_old</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_state_new</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#mlpro.rl.models_env.Reward" title="mlpro.rl.models_env.Reward">mlpro.rl.models_env.Reward</a><a class="headerlink" href="#mlpro.rl.models_env.FctReward.compute_reward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a reward based on a predecessor and successor state. Custom method _compute_reward()
is called.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_state_old</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – Predecessor state.</p></li>
<li><p><strong>p_state_new</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – Successor state.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>r</strong> – Reward</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#mlpro.rl.models_env.Reward" title="mlpro.rl.models_env.Reward">Reward</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_env.EnvBase">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env.</code><code class="sig-name descname">EnvBase</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_mode</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_latency</span><span class="p">:</span> <span class="n">datetime.timedelta</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_fct_strans</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctSTrans" title="mlpro.bf.systems.FctSTrans">mlpro.bf.systems.FctSTrans</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_fct_reward</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_env.FctReward" title="mlpro.rl.models_env.FctReward">mlpro.rl.models_env.FctReward</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_fct_success</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctSuccess" title="mlpro.bf.systems.FctSuccess">mlpro.bf.systems.FctSuccess</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_fct_broken</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctBroken" title="mlpro.bf.systems.FctBroken">mlpro.bf.systems.FctBroken</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_visualize</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.EnvBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.System" title="mlpro.bf.systems.System"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.systems.System</span></code></a>, <a class="reference internal" href="#mlpro.rl.models_env.FctReward" title="mlpro.rl.models_env.FctReward"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_env.FctReward</span></code></a></p>
<p>Base class for all environment classes. It defines the interface and elementary properties for
an environment in the context of reinforcement learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_latency</strong> (<em>timedelta</em>) – Optional latency of environment. If not provided, the internal value of constant C_LATENCY
is used by default.</p></li>
<li><p><strong>p_fct_strans</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctSTrans" title="mlpro.bf.systems.FctSTrans"><em>FctSTrans</em></a>) – Optional external function for state transition.</p></li>
<li><p><strong>p_fct_reward</strong> (<a class="reference internal" href="#mlpro.rl.models_env.FctReward" title="mlpro.rl.models_env.FctReward"><em>FctReward</em></a>) – Optional external function for reward computation.</p></li>
<li><p><strong>p_fct_success</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctSuccess" title="mlpro.bf.systems.FctSuccess"><em>FctSuccess</em></a>) – Optional external function for state evaluation ‘success’.</p></li>
<li><p><strong>p_fct_broken</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctBroken" title="mlpro.bf.systems.FctBroken"><em>FctBroken</em></a>) – Optional external function for state evaluation ‘broken’.</p></li>
<li><p><strong>p_visualize</strong> (<em>bool</em>) – Boolean switch for env/agent visualisation. Default = False.</p></li>
<li><p><strong>p_logging</strong> – Log level (see class Log for more details).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_env.EnvBase._latency">
<code class="sig-name descname">_latency</code><a class="headerlink" href="#mlpro.rl.models_env.EnvBase._latency" title="Permalink to this definition">¶</a></dt>
<dd><p>Latency of the environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>timedelta</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.EnvBase._state">
<code class="sig-name descname">_state</code><a class="headerlink" href="#mlpro.rl.models_env.EnvBase._state" title="Permalink to this definition">¶</a></dt>
<dd><p>Current state of environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">State</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="id0">
<code class="sig-name descname">_state</code><a class="headerlink" href="#id0" title="Permalink to this definition">¶</a></dt>
<dd><p>Previous state of environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">State</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.EnvBase._last_action">
<code class="sig-name descname">_last_action</code><a class="headerlink" href="#mlpro.rl.models_env.EnvBase._last_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Last action.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action">Action</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.EnvBase._last_reward">
<code class="sig-name descname">_last_reward</code><a class="headerlink" href="#mlpro.rl.models_env.EnvBase._last_reward" title="Permalink to this definition">¶</a></dt>
<dd><p>Last reward.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#mlpro.rl.models_env.Reward" title="mlpro.rl.models_env.Reward">Reward</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.EnvBase._afct_strans">
<code class="sig-name descname">_afct_strans</code><a class="headerlink" href="#mlpro.rl.models_env.EnvBase._afct_strans" title="Permalink to this definition">¶</a></dt>
<dd><p>Internal adaptive state transition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#mlpro.rl.models_env_ada.AFctSTrans" title="mlpro.rl.models_env_ada.AFctSTrans">AFctSTrans</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.EnvBase._afct_reward">
<code class="sig-name descname">_afct_reward</code><a class="headerlink" href="#mlpro.rl.models_env.EnvBase._afct_reward" title="Permalink to this definition">¶</a></dt>
<dd><p>Internal adaptive reward function.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#mlpro.rl.models_env_ada.AFctReward" title="mlpro.rl.models_env_ada.AFctReward">AFctReward</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.EnvBase._afct_success">
<code class="sig-name descname">_afct_success</code><a class="headerlink" href="#mlpro.rl.models_env.EnvBase._afct_success" title="Permalink to this definition">¶</a></dt>
<dd><p>Internal adaptive function for state evaluation ‘success’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#mlpro.rl.models_env_ada.AFctSuccess" title="mlpro.rl.models_env_ada.AFctSuccess">AFctSuccess</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.EnvBase._afct_broken">
<code class="sig-name descname">_afct_broken</code><a class="headerlink" href="#mlpro.rl.models_env.EnvBase._afct_broken" title="Permalink to this definition">¶</a></dt>
<dd><p>Internal adaptive function for state evaluation ‘broken’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#mlpro.rl.models_env_ada.AFctBroken" title="mlpro.rl.models_env_ada.AFctBroken">AFctBroken</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.EnvBase.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'Environment Base'</em><a class="headerlink" href="#mlpro.rl.models_env.EnvBase.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.EnvBase.C_REWARD_TYPE">
<code class="sig-name descname">C_REWARD_TYPE</code><em class="property"> = 0</em><a class="headerlink" href="#mlpro.rl.models_env.EnvBase.C_REWARD_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.EnvBase.switch_logging">
<code class="sig-name descname">switch_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_logging</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.EnvBase.switch_logging" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets new log level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_logging</strong> – Log level (constant C_LOG_LEVELS contains valid values)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.EnvBase.get_reward_type">
<code class="sig-name descname">get_reward_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.EnvBase.get_reward_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.EnvBase.get_last_reward">
<code class="sig-name descname">get_last_reward</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#mlpro.rl.models_env.Reward" title="mlpro.rl.models_env.Reward">mlpro.rl.models_env.Reward</a><a class="headerlink" href="#mlpro.rl.models_env.EnvBase.get_last_reward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.EnvBase.get_functions">
<code class="sig-name descname">get_functions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.EnvBase.get_functions" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.EnvBase.get_cycle_limit">
<code class="sig-name descname">get_cycle_limit</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#mlpro.rl.models_env.EnvBase.get_cycle_limit" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns limit of cycles per training episode. To be implemented in child classes.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.EnvBase.compute_reward">
<code class="sig-name descname">compute_reward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_state_old</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_state_new</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#mlpro.rl.models_env.Reward" title="mlpro.rl.models_env.Reward">mlpro.rl.models_env.Reward</a><a class="headerlink" href="#mlpro.rl.models_env.EnvBase.compute_reward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a reward for the state transition, given by two successive states. The reward
computation itself is carried out either by a custom implementation in method
_compute_reward() or by an embedded adaptive function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_state_old</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – Optional state before transition. If None the internal previous state of the environment
is used.</p></li>
<li><p><strong>p_state_new</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – Optional tate after transition. If None the internal current state of the environment
is used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Reward object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#mlpro.rl.models_env.Reward" title="mlpro.rl.models_env.Reward">Reward</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_env.Environment">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env.</code><code class="sig-name descname">Environment</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_mode</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_latency</span><span class="p">:</span> <span class="n">datetime.timedelta</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_fct_strans</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctSTrans" title="mlpro.bf.systems.FctSTrans">mlpro.bf.systems.FctSTrans</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_fct_reward</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_env.FctReward" title="mlpro.rl.models_env.FctReward">mlpro.rl.models_env.FctReward</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_fct_success</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctSuccess" title="mlpro.bf.systems.FctSuccess">mlpro.bf.systems.FctSuccess</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_fct_broken</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctBroken" title="mlpro.bf.systems.FctBroken">mlpro.bf.systems.FctBroken</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_visualize</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.Environment" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mlpro.rl.models_env.EnvBase" title="mlpro.rl.models_env.EnvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_env.EnvBase</span></code></a></p>
<p>This class represents the central environment model to be reused/inherited in own rl projects.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_mode</strong> – Mode of environment. Possible values are Mode.C_MODE_SIM(default) or Mode.C_MODE_REAL.</p></li>
<li><p><strong>p_latency</strong> (<em>timedelta</em>) – Optional latency of environment. If not provided, the internal value of constant C_LATENCY
is used by default.</p></li>
<li><p><strong>p_fct_strans</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctSTrans" title="mlpro.bf.systems.FctSTrans"><em>FctSTrans</em></a>) – Optional external function for state transition.</p></li>
<li><p><strong>p_fct_reward</strong> (<a class="reference internal" href="#mlpro.rl.models_env.FctReward" title="mlpro.rl.models_env.FctReward"><em>FctReward</em></a>) – Optional external function for reward computation.</p></li>
<li><p><strong>p_fct_success</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctSuccess" title="mlpro.bf.systems.FctSuccess"><em>FctSuccess</em></a>) – Optional external function for state evaluation ‘success’.</p></li>
<li><p><strong>p_fct_broken</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctBroken" title="mlpro.bf.systems.FctBroken"><em>FctBroken</em></a>) – Optional external function for state evaluation ‘broken’.</p></li>
<li><p><strong>p_visualize</strong> (<em>bool</em>) – Boolean switch for env/agent visualisation. Default = True.</p></li>
<li><p><strong>p_logging</strong> – Log level (see class Log for more details)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_env.Environment.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'Environment'</em><a class="headerlink" href="#mlpro.rl.models_env.Environment.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env.Environment.C_CYCLE_LIMIT">
<code class="sig-name descname">C_CYCLE_LIMIT</code><em class="property"> = 0</em><a class="headerlink" href="#mlpro.rl.models_env.Environment.C_CYCLE_LIMIT" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.Environment.setup_spaces">
<em class="property">static </em><code class="sig-name descname">setup_spaces</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env.Environment.setup_spaces" title="Permalink to this definition">¶</a></dt>
<dd><p>Static template method to set up and return state and action space of environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>state_space</strong> (<em>MSpace</em>) – State space object</p></li>
<li><p><strong>action_space</strong> (<em>MSpace</em>) – Action space object</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env.Environment.get_cycle_limit">
<code class="sig-name descname">get_cycle_limit</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#mlpro.rl.models_env.Environment.get_cycle_limit" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns limit of cycles per training episode.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="adaptive-environments">
<h2>Adaptive Environments<a class="headerlink" href="#adaptive-environments" title="Permalink to this headline">¶</a></h2>
<img alt="../../../../../_images/MLPro-RL-Env-Ada_class_diagram.drawio.png" src="../../../../../_images/MLPro-RL-Env-Ada_class_diagram.drawio.png" />
<span class="target" id="module-mlpro.rl.models_env_ada"></span><p>Ver. 1.0.0 (2022-11-29)</p>
<p>This module provides model classes for adaptive environment models.</p>
<dl class="py class">
<dt id="mlpro.rl.models_env_ada.AFctBase">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env_ada.</code><code class="sig-name descname">AFctBase</code><span class="sig-paren">(</span><em class="sig-param">p_afct_cls</em>, <em class="sig-param">p_state_space: mlpro.bf.math.basics.MSpace</em>, <em class="sig-param">p_action_space: mlpro.bf.math.basics.MSpace</em>, <em class="sig-param">p_input_space_cls=&lt;class 'mlpro.bf.math.basics.ESpace'&gt;</em>, <em class="sig-param">p_output_space_cls=&lt;class 'mlpro.bf.math.basics.ESpace'&gt;</em>, <em class="sig-param">p_output_elem_cls=&lt;class 'mlpro.bf.math.basics.Element'&gt;</em>, <em class="sig-param">p_threshold=0</em>, <em class="sig-param">p_buffer_size=0</em>, <em class="sig-param">p_ada: bool = True</em>, <em class="sig-param">p_visualize: bool = False</em>, <em class="sig-param">p_logging=True</em>, <em class="sig-param">**p_kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.ml.basics.Model</span></code></p>
<p>Base class for all special adaptive functions (state transition, reward, success, broken).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_afct_cls</strong> – Adaptive function class (compatible to class mlpro.sl.SLAdaptiveFunction)</p></li>
<li><p><strong>p_state_space</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace"><em>MSpace</em></a>) – State space of an environment or observation space of an agent</p></li>
<li><p><strong>p_action_space</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace"><em>MSpace</em></a>) – Action space of an environment or agent</p></li>
<li><p><strong>p_input_space_cls</strong> – Space class that is used for the generated input space of the embedded adaptive function (compatible to class
MSpace)</p></li>
<li><p><strong>p_output_space_cls</strong> – Space class that is used for the generated output space of the embedded adaptive function (compatible to class
MSpace)</p></li>
<li><p><strong>p_output_elem_cls</strong> – Output element class (compatible to/inherited from class Element)</p></li>
<li><p><strong>p_threshold</strong> (<em>float</em>) – Threshold for the difference between a set point and a computed output. Computed outputs with
a difference less than this threshold will be assessed as ‘good’ outputs. Default = 0.</p></li>
<li><p><strong>p_buffer_size</strong> (<em>int</em>) – Initial size of internal data buffer. Default = 0 (no buffering).</p></li>
<li><p><strong>p_ada</strong> (<em>bool</em>) – Boolean switch for adaptivity. Default = True.</p></li>
<li><p><strong>p_visualize</strong> (<em>bool</em>) – Boolean switch for visualisation. Default = False.</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class Log). Default: Log.C_LOG_ALL</p></li>
<li><p><strong>p_kwargs</strong> (<em>Dict</em>) – Further model specific parameters (to be specified in child class).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.AFctBase._state_space">
<code class="sig-name descname">_state_space</code><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase._state_space" title="Permalink to this definition">¶</a></dt>
<dd><p>State space</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">MSpace</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.AFctBase._action_space">
<code class="sig-name descname">_action_space</code><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase._action_space" title="Permalink to this definition">¶</a></dt>
<dd><p>Action space</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">MSpace</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.AFctBase._input_space">
<code class="sig-name descname">_input_space</code><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase._input_space" title="Permalink to this definition">¶</a></dt>
<dd><p>Input space of embedded adaptive function</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">MSpace</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.AFctBase._output_space">
<code class="sig-name descname">_output_space</code><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase._output_space" title="Permalink to this definition">¶</a></dt>
<dd><p>Output space oof embedded adaptive function</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">MSpace</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.AFctBase._afct">
<code class="sig-name descname">_afct</code><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase._afct" title="Permalink to this definition">¶</a></dt>
<dd><p>Embedded adaptive function</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.sl.html#mlpro.sl.models.SLAdaptiveFunction" title="mlpro.sl.models.SLAdaptiveFunction">SLAdaptiveFunction</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.AFctBase.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'AFct Base'</em><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.get_afct">
<code class="sig-name descname">get_afct</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.sl.html#mlpro.sl.models.SLAdaptiveFunction" title="mlpro.sl.models.SLAdaptiveFunction">mlpro.sl.models.SLAdaptiveFunction</a><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.get_afct" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.get_state_space">
<code class="sig-name descname">get_state_space</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.get_state_space" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.get_action_space">
<code class="sig-name descname">get_action_space</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.get_action_space" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.get_hyperparam">
<code class="sig-name descname">get_hyperparam</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; mlpro.bf.ml.basics.HyperParamTuple<a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.get_hyperparam" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the internal hyperparameter tuple to get access to single values.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.switch_adaptivity">
<code class="sig-name descname">switch_adaptivity</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_ada</span><span class="p">:</span> <span class="n">bool</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.switch_adaptivity" title="Permalink to this definition">¶</a></dt>
<dd><p>Switches adaption functionality on/off.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_ada</strong> (<em>bool</em>) – Boolean switch for adaptivity</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.switch_logging">
<code class="sig-name descname">switch_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_logging</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.switch_logging" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets new log level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_logging</strong> – Log level (constant C_LOG_LEVELS contains valid values)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.set_random_seed">
<code class="sig-name descname">set_random_seed</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_seed</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.set_random_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the internal random generator using the given seed.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.get_adapted">
<code class="sig-name descname">get_adapted</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.get_adapted" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True, if the model was adapted at least once. False otherwise.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.clear_buffer">
<code class="sig-name descname">clear_buffer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.clear_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Clears internal buffer (if buffering is active).</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.get_accuracy">
<code class="sig-name descname">get_accuracy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.get_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the accuracy of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Accuracy of the model as a scalar value in interval [0,1]</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.init_plot">
<code class="sig-name descname">init_plot</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_figure</span><span class="p">:</span> <span class="n">matplotlib.figure.Figure</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_plot_settings</span><span class="p">:</span> <span class="n">list</span> <span class="o">=</span> <span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">p_plot_depth</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_detail_level</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_step_rate</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">p_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.init_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes the plot functionalities of the class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_figure</strong> (<em>Matplotlib.figure.Figure</em><em>, </em><em>optional</em>) – Optional MatPlotLib host figure, where the plot shall be embedded. The default is None.</p></li>
<li><p><strong>p_plot_settings</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.plot.PlotSettings" title="mlpro.bf.plot.PlotSettings"><em>PlotSettings</em></a>) – Optional plot settings. If None, the default view is plotted (see attribute C_PLOT_DEFAULT_VIEW).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.AFctBase.update_plot">
<code class="sig-name descname">update_plot</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">p_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBase.update_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the plot.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>**p_kwargs</strong> – Implementation-specific plot data and/or parameters.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_env_ada.AFctSTrans">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env_ada.</code><code class="sig-name descname">AFctSTrans</code><span class="sig-paren">(</span><em class="sig-param">p_afct_cls</em>, <em class="sig-param">p_state_space: mlpro.bf.math.basics.MSpace</em>, <em class="sig-param">p_action_space: mlpro.bf.math.basics.MSpace</em>, <em class="sig-param">p_input_space_cls=&lt;class 'mlpro.bf.math.basics.ESpace'&gt;</em>, <em class="sig-param">p_output_space_cls=&lt;class 'mlpro.bf.math.basics.ESpace'&gt;</em>, <em class="sig-param">p_output_elem_cls=&lt;class 'mlpro.bf.systems.State'&gt;</em>, <em class="sig-param">p_threshold=0</em>, <em class="sig-param">p_buffer_size=0</em>, <em class="sig-param">p_ada: bool = True</em>, <em class="sig-param">p_visualize: bool = False</em>, <em class="sig-param">p_logging=True</em>, <em class="sig-param">**p_par</em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctSTrans" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mlpro.rl.models_env_ada.AFctBase" title="mlpro.rl.models_env_ada.AFctBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_env_ada.AFctBase</span></code></a>, <a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctSTrans" title="mlpro.bf.systems.FctSTrans"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.systems.FctSTrans</span></code></a></p>
<p>Online adaptive version of a state transition function. See parent classes for further details.</p>
<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.AFctSTrans.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'AFct STrans'</em><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctSTrans.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_env_ada.AFctSuccess">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env_ada.</code><code class="sig-name descname">AFctSuccess</code><span class="sig-paren">(</span><em class="sig-param">p_afct_cls</em>, <em class="sig-param">p_state_space: mlpro.bf.math.basics.MSpace</em>, <em class="sig-param">p_action_space: mlpro.bf.math.basics.MSpace</em>, <em class="sig-param">p_input_space_cls=&lt;class 'mlpro.bf.math.basics.ESpace'&gt;</em>, <em class="sig-param">p_output_space_cls=&lt;class 'mlpro.bf.math.basics.ESpace'&gt;</em>, <em class="sig-param">p_output_elem_cls=&lt;class 'mlpro.bf.math.basics.Element'&gt;</em>, <em class="sig-param">p_threshold=0</em>, <em class="sig-param">p_buffer_size=0</em>, <em class="sig-param">p_ada: bool = True</em>, <em class="sig-param">p_visualize: bool = False</em>, <em class="sig-param">p_logging=True</em>, <em class="sig-param">**p_kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctSuccess" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mlpro.rl.models_env_ada.AFctBase" title="mlpro.rl.models_env_ada.AFctBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_env_ada.AFctBase</span></code></a>, <a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctSuccess" title="mlpro.bf.systems.FctSuccess"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.systems.FctSuccess</span></code></a></p>
<p>Online adaptive version of a function that determine whether or not a state is a success state.
See parent classes for further details.</p>
<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.AFctSuccess.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'AFct Success'</em><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctSuccess.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_env_ada.AFctBroken">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env_ada.</code><code class="sig-name descname">AFctBroken</code><span class="sig-paren">(</span><em class="sig-param">p_afct_cls</em>, <em class="sig-param">p_state_space: mlpro.bf.math.basics.MSpace</em>, <em class="sig-param">p_action_space: mlpro.bf.math.basics.MSpace</em>, <em class="sig-param">p_input_space_cls=&lt;class 'mlpro.bf.math.basics.ESpace'&gt;</em>, <em class="sig-param">p_output_space_cls=&lt;class 'mlpro.bf.math.basics.ESpace'&gt;</em>, <em class="sig-param">p_output_elem_cls=&lt;class 'mlpro.bf.math.basics.Element'&gt;</em>, <em class="sig-param">p_threshold=0</em>, <em class="sig-param">p_buffer_size=0</em>, <em class="sig-param">p_ada: bool = True</em>, <em class="sig-param">p_visualize: bool = False</em>, <em class="sig-param">p_logging=True</em>, <em class="sig-param">**p_kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBroken" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mlpro.rl.models_env_ada.AFctBase" title="mlpro.rl.models_env_ada.AFctBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_env_ada.AFctBase</span></code></a>, <a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.FctBroken" title="mlpro.bf.systems.FctBroken"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.systems.FctBroken</span></code></a></p>
<p>Online adaptive version of a function that determine whether or not a state is a broken state.
See parent classes for further details.</p>
<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.AFctBroken.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'AFct Broken'</em><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctBroken.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_env_ada.AFctReward">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env_ada.</code><code class="sig-name descname">AFctReward</code><span class="sig-paren">(</span><em class="sig-param">p_afct_cls</em>, <em class="sig-param">p_state_space: mlpro.bf.math.basics.MSpace</em>, <em class="sig-param">p_action_space: mlpro.bf.math.basics.MSpace</em>, <em class="sig-param">p_input_space_cls=&lt;class 'mlpro.bf.math.basics.ESpace'&gt;</em>, <em class="sig-param">p_output_space_cls=&lt;class 'mlpro.bf.math.basics.ESpace'&gt;</em>, <em class="sig-param">p_output_elem_cls=&lt;class 'mlpro.bf.math.basics.Element'&gt;</em>, <em class="sig-param">p_threshold=0</em>, <em class="sig-param">p_buffer_size=0</em>, <em class="sig-param">p_ada: bool = True</em>, <em class="sig-param">p_visualize: bool = False</em>, <em class="sig-param">p_logging=True</em>, <em class="sig-param">**p_kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctReward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mlpro.rl.models_env_ada.AFctBase" title="mlpro.rl.models_env_ada.AFctBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_env_ada.AFctBase</span></code></a>, <a class="reference internal" href="#mlpro.rl.models_env.FctReward" title="mlpro.rl.models_env.FctReward"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_env.FctReward</span></code></a></p>
<p>Online adaptive version of a reward function. See parent classes for further details.</p>
<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.AFctReward.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'AFct Reward'</em><a class="headerlink" href="#mlpro.rl.models_env_ada.AFctReward.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_env_ada.SARSElement">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env_ada.</code><code class="sig-name descname">SARSElement</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_state</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span></em>, <em class="sig-param"><span class="n">p_action</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action">mlpro.bf.systems.Action</a></span></em>, <em class="sig-param"><span class="n">p_reward</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_env.Reward" title="mlpro.rl.models_env.Reward">mlpro.rl.models_env.Reward</a></span></em>, <em class="sig-param"><span class="n">p_state_new</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.SARSElement" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="mlpro.bf.html#mlpro.bf.data.BufferElement" title="mlpro.bf.data.BufferElement"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.data.BufferElement</span></code></a></p>
<p>Element of a SARSBuffer.</p>
</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_env_ada.SARSBuffer">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env_ada.</code><code class="sig-name descname">SARSBuffer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_size</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.SARSBuffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="mlpro.bf.html#mlpro.bf.data.Buffer" title="mlpro.bf.data.Buffer"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.data.Buffer</span></code></a></p>
<p>State-Action-Reward-State-Buffer in dictionary.</p>
</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_env_ada.EnvModel">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_env_ada.</code><code class="sig-name descname">EnvModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_observation_space</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a></span></em>, <em class="sig-param"><span class="n">p_action_space</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a></span></em>, <em class="sig-param"><span class="n">p_latency</span><span class="p">:</span> <span class="n">datetime.timedelta</span></em>, <em class="sig-param"><span class="n">p_afct_strans</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_env_ada.AFctSTrans" title="mlpro.rl.models_env_ada.AFctSTrans">mlpro.rl.models_env_ada.AFctSTrans</a></span></em>, <em class="sig-param"><span class="n">p_afct_reward</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_env_ada.AFctReward" title="mlpro.rl.models_env_ada.AFctReward">mlpro.rl.models_env_ada.AFctReward</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_afct_success</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_env_ada.AFctSuccess" title="mlpro.rl.models_env_ada.AFctSuccess">mlpro.rl.models_env_ada.AFctSuccess</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_afct_broken</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_env_ada.AFctBroken" title="mlpro.rl.models_env_ada.AFctBroken">mlpro.rl.models_env_ada.AFctBroken</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_ada</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">p_visualize</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.EnvModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mlpro.rl.models_env.EnvBase" title="mlpro.rl.models_env.EnvBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_env.EnvBase</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.ml.basics.Model</span></code></p>
<p>Environment model class as part of a model-based agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_observation_space</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace"><em>MSpace</em></a>) – Observation space of related agent.</p></li>
<li><p><strong>p_action_space</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace"><em>MSpace</em></a>) – Action space of related agent.</p></li>
<li><p><strong>p_latency</strong> (<em>timedelta</em>) – Latency of related environment.</p></li>
<li><p><strong>p_afct_strans</strong> (<a class="reference internal" href="#mlpro.rl.models_env_ada.AFctSTrans" title="mlpro.rl.models_env_ada.AFctSTrans"><em>AFctSTrans</em></a>) – Mandatory external adaptive function for state transition.</p></li>
<li><p><strong>p_afct_reward</strong> (<a class="reference internal" href="#mlpro.rl.models_env_ada.AFctReward" title="mlpro.rl.models_env_ada.AFctReward"><em>AFctReward</em></a>) – Optional external adaptive function for reward computation.</p></li>
<li><p><strong>p_afct_success</strong> (<a class="reference internal" href="#mlpro.rl.models_env_ada.AFctSuccess" title="mlpro.rl.models_env_ada.AFctSuccess"><em>AFctSuccess</em></a>) – Optional external adaptive function for state assessment ‘success’.</p></li>
<li><p><strong>p_afct_broken</strong> (<a class="reference internal" href="#mlpro.rl.models_env_ada.AFctBroken" title="mlpro.rl.models_env_ada.AFctBroken"><em>AFctBroken</em></a>) – Optional external adaptive function for state assessment ‘broken’.</p></li>
<li><p><strong>p_ada</strong> (<em>bool</em>) – Boolean switch for adaptivity.</p></li>
<li><p><strong>p_visualize</strong> (<em>bool</em>) – Boolean switch for env/agent visualisation. Default = False.</p></li>
<li><p><strong>p_logging</strong> – Log level (see class Log for more details).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.EnvModel.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'EnvModel'</em><a class="headerlink" href="#mlpro.rl.models_env_ada.EnvModel.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_env_ada.EnvModel.C_NAME">
<code class="sig-name descname">C_NAME</code><em class="property"> = 'Default'</em><a class="headerlink" href="#mlpro.rl.models_env_ada.EnvModel.C_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.EnvModel.setup_spaces">
<em class="property">static </em><code class="sig-name descname">setup_spaces</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.EnvModel.setup_spaces" title="Permalink to this definition">¶</a></dt>
<dd><p>Static template method to set up and return state and action space of environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>state_space</strong> (<em>MSpace</em>) – State space object</p></li>
<li><p><strong>action_space</strong> (<em>MSpace</em>) – Action space object</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.EnvModel.get_cycle_limit">
<code class="sig-name descname">get_cycle_limit</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#mlpro.rl.models_env_ada.EnvModel.get_cycle_limit" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns limit of cycles per training episode.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.EnvModel.switch_adaptivity">
<code class="sig-name descname">switch_adaptivity</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_ada</span><span class="p">:</span> <span class="n">bool</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.EnvModel.switch_adaptivity" title="Permalink to this definition">¶</a></dt>
<dd><p>Switches adaption functionality on/off.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_ada</strong> (<em>bool</em>) – Boolean switch for adaptivity</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.EnvModel.adapt">
<code class="sig-name descname">adapt</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">p_kwargs</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.rl.models_env_ada.EnvModel.adapt" title="Permalink to this definition">¶</a></dt>
<dd><p>Reactivated adaptation mechanism. See method Model.adapt() for further details.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.EnvModel.get_adapted">
<code class="sig-name descname">get_adapted</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.rl.models_env_ada.EnvModel.get_adapted" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True, if the model was adapted at least once. False otherwise.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.EnvModel.get_accuracy">
<code class="sig-name descname">get_accuracy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.EnvModel.get_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns accuracy of environment model as average accuracy of the embedded adaptive functions.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_env_ada.EnvModel.clear_buffer">
<code class="sig-name descname">clear_buffer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_env_ada.EnvModel.clear_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Clears internal buffer (if buffering is active).</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="agents">
<h2>Agents<a class="headerlink" href="#agents" title="Permalink to this headline">¶</a></h2>
<img alt="../../../../../_images/MLPro-RL-Agents_class_diagram.drawio.png" src="../../../../../_images/MLPro-RL-Agents_class_diagram.drawio.png" />
<span class="target" id="module-mlpro.rl.models_agents"></span><p>Ver. 1.6.3 (2022-12-09)</p>
<p>This module provides model classes for policies, model-free and model-based agents and multi-agents.</p>
<dl class="py class">
<dt id="mlpro.rl.models_agents.Policy">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_agents.</code><code class="sig-name descname">Policy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_observation_space</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a></span></em>, <em class="sig-param"><span class="n">p_action_space</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a></span></em>, <em class="sig-param"><span class="n">p_buffer_size</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">p_ada</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">p_visualize</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Policy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.ml.basics.Model</span></code></p>
<p>This class represents the policy of a single-agent. It is adaptive and can be trained with
State-Action-Reward (SAR) data that will be expected as a SAR buffer object.
The three main learning paradigms of machine learning to train a policy are supported:</p>
<p>a) Training by Supervised Learning
The entire SAR data set inside the SAR buffer shall be adapted.</p>
<p>b) Training by Reinforcement Learning
The latest SAR data record inside the SAR buffer shall be adapted.</p>
<p>c) Training by Unsupervised Learning
All state data inside the SAR buffer shall be adapted.</p>
<p>Furthermore, a policy class can compute actions from states.</p>
<p>Hyperparameters of the policy should be stored in the internal object self._hp_list, so that
they can be tuned from outside. Optionally a policy-specific callback method can be called on
changes. For more information see class HyperParameterList.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_observation_space</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace"><em>MSpace</em></a>) – Subspace of an environment that is observed by the policy.</p></li>
<li><p><strong>p_action_space</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace"><em>MSpace</em></a>) – Action space object.</p></li>
<li><p><strong>p_buffer_size</strong> (<em>int</em>) – Size of internal buffer. Default = 1.</p></li>
<li><p><strong>p_ada</strong> (<em>bool</em>) – Boolean switch for adaptivity. Default = True.</p></li>
<li><p><strong>p_visualize</strong> (<em>bool</em>) – Boolean switch for env/agent visualisation. Default = False.</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class Log). Default = Log.C_LOG_ALL.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_agents.Policy.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'Policy'</em><a class="headerlink" href="#mlpro.rl.models_agents.Policy.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_agents.Policy.C_NAME">
<code class="sig-name descname">C_NAME</code><em class="property"> = '????'</em><a class="headerlink" href="#mlpro.rl.models_agents.Policy.C_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_agents.Policy.C_BUFFER_CLS">
<code class="sig-name descname">C_BUFFER_CLS</code><a class="headerlink" href="#mlpro.rl.models_agents.Policy.C_BUFFER_CLS" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#mlpro.rl.models_env_ada.SARSBuffer" title="mlpro.rl.models_env_ada.SARSBuffer"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_env_ada.SARSBuffer</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Policy.get_observation_space">
<code class="sig-name descname">get_observation_space</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a><a class="headerlink" href="#mlpro.rl.models_agents.Policy.get_observation_space" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Policy.get_action_space">
<code class="sig-name descname">get_action_space</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a><a class="headerlink" href="#mlpro.rl.models_agents.Policy.get_action_space" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Policy.get_id">
<code class="sig-name descname">get_id</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Policy.get_id" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Policy.set_id">
<code class="sig-name descname">set_id</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_id</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Policy.set_id" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Policy.compute_action">
<code class="sig-name descname">compute_action</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_obs</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action">mlpro.bf.systems.Action</a><a class="headerlink" href="#mlpro.rl.models_agents.Policy.compute_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Specific action computation method to be redefined.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_obs</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – Observation data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>action</strong> – Action object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action">Action</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_agents.ActionPlanner">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_agents.</code><code class="sig-name descname">ActionPlanner</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_state_thsld</span><span class="o">=</span><span class="default_value">1e-08</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.ActionPlanner" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="mlpro.bf.html#mlpro.bf.various.Log" title="mlpro.bf.various.Log"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.various.Log</span></code></a></p>
<p>Template class for action planning algorithms to be used as part of model-based planning agents.
The goal is to find the shortest sequence of actions that leads to a maximum reward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_state_thsld</strong> (<em>float</em>) – Threshold for metric difference between two states to be equal. Default = 0.00000001.</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class Log). Default = Log.C_LOG_ALL.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_agents.ActionPlanner.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'Action Planner'</em><a class="headerlink" href="#mlpro.rl.models_agents.ActionPlanner.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.ActionPlanner.setup">
<code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_policy</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_agents.Policy" title="mlpro.rl.models_agents.Policy">mlpro.rl.models_agents.Policy</a></span></em>, <em class="sig-param"><span class="n">p_envmodel</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_env_ada.EnvModel" title="mlpro.rl.models_env_ada.EnvModel">mlpro.rl.models_env_ada.EnvModel</a></span></em>, <em class="sig-param"><span class="n">p_prediction_horizon</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_control_horizon</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_width_limit</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.ActionPlanner.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Setup of action planner object in concrete planning scenario. Must be called before first
planning. Optional custom method _setup() is called at the end.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_policy</strong> (<a class="reference internal" href="#mlpro.rl.models_agents.Policy" title="mlpro.rl.models_agents.Policy"><em>Policy</em></a>) – Policy of an agent.</p></li>
<li><p><strong>p_envmodel</strong> (<a class="reference internal" href="#mlpro.rl.models_env_ada.EnvModel" title="mlpro.rl.models_env_ada.EnvModel"><em>EnvModel</em></a>) – Environment model.</p></li>
<li><p><strong>p_prediction_horizon</strong> (<em>int</em>) – Optional static maximum planning depth (=length of action path to be predicted). Can
be overridden by method compute_action(). Default=0.</p></li>
<li><p><strong>p_control_horizon</strong> (<em>int</em>) – The length of predicted action path to be applied. Can be overridden by method
compute_action(). Default=0.</p></li>
<li><p><strong>p_width_limit</strong> (<em>int</em>) – Optional static maximum planning width (=number of alternative actions per planning level).
Can be overridden by method compute_action(). Default=0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.ActionPlanner.compute_action">
<code class="sig-name descname">compute_action</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_obs</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span></em>, <em class="sig-param"><span class="n">p_prediction_horizon</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_control_horizon</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_width_limit</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action">mlpro.bf.systems.Action</a><a class="headerlink" href="#mlpro.rl.models_agents.ActionPlanner.compute_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a path of actions with defined length that maximizes the reward of the given
environment model. The planning algorithm itself is to be implemented in the custom method
_plan_action().</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_obs</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – Observation data.</p></li>
<li><p><strong>p_prediction_horizon</strong> (<em>int</em>) – Optional dynamic maximum planning depth (=length of action path to be predicted) that
overrides the static limit of method setup(). Default=0 (no override).</p></li>
<li><p><strong>p_control_horizon</strong> (<em>int</em>) – The length of predicted action path to be applied that overrides the static limit of
method setup(). Default=0 (no override).</p></li>
<li><p><strong>p_width_limit</strong> (<em>int</em>) – Optional dynamic maximum planning width (=number of alternative actions per planning level)
that overrides the static limit of method setup(). Default=0 (no override).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>action</strong> – Best action as result of the planning process.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action">Action</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.ActionPlanner.clear_action_path">
<code class="sig-name descname">clear_action_path</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.ActionPlanner.clear_action_path" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_agents.RLScenarioMBInt">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_agents.</code><code class="sig-name descname">RLScenarioMBInt</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_mode</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_ada</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">p_cycle_limit</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_visualize</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.RLScenarioMBInt" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mlpro.rl.models_train.RLScenario" title="mlpro.rl.models_train.RLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_train.RLScenario</span></code></a></p>
<p>Internal use in class Agent. Intended for the training of the policy with the environment model of
a model-based (single) agent.</p>
<dl class="py attribute">
<dt id="mlpro.rl.models_agents.RLScenarioMBInt.C_NAME">
<code class="sig-name descname">C_NAME</code><em class="property"> = 'MB(intern)'</em><a class="headerlink" href="#mlpro.rl.models_agents.RLScenarioMBInt.C_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.RLScenarioMBInt.setup_ext">
<code class="sig-name descname">setup_ext</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_env</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_env.EnvBase" title="mlpro.rl.models_env.EnvBase">mlpro.rl.models_env.EnvBase</a></span></em>, <em class="sig-param"><span class="n">p_policy</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_agents.Policy" title="mlpro.rl.models_agents.Policy">mlpro.rl.models_agents.Policy</a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.RLScenarioMBInt.setup_ext" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_agents.Agent">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_agents.</code><code class="sig-name descname">Agent</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_policy</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_agents.Policy" title="mlpro.rl.models_agents.Policy">mlpro.rl.models_agents.Policy</a></span></em>, <em class="sig-param"><span class="n">p_envmodel</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_env_ada.EnvModel" title="mlpro.rl.models_env_ada.EnvModel">mlpro.rl.models_env_ada.EnvModel</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_em_acc_thsld</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">p_action_planner</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_agents.ActionPlanner" title="mlpro.rl.models_agents.ActionPlanner">mlpro.rl.models_agents.ActionPlanner</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_predicting_horizon</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_controlling_horizon</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_planning_width</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_name</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">p_id</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_ada</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">p_visualize</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">p_mb_training_param</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Agent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mlpro.rl.models_agents.Policy" title="mlpro.rl.models_agents.Policy"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_agents.Policy</span></code></a></p>
<p>This class represents a single agent model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_policy</strong> (<a class="reference internal" href="#mlpro.rl.models_agents.Policy" title="mlpro.rl.models_agents.Policy"><em>Policy</em></a>) – Policy object.</p></li>
<li><p><strong>p_envmodel</strong> (<a class="reference internal" href="#mlpro.rl.models_env_ada.EnvModel" title="mlpro.rl.models_env_ada.EnvModel"><em>EnvModel</em></a>) – Optional environment model object. Default = None.</p></li>
<li><p><strong>p_em_acc_thsld</strong> (<em>float</em>) – Optional threshold for environment model accuracy (whether the envmodel is ‘good’
enough to be used to train the policy). Default = 0.9.</p></li>
<li><p><strong>p_action_planner</strong> (<a class="reference internal" href="#mlpro.rl.models_agents.ActionPlanner" title="mlpro.rl.models_agents.ActionPlanner"><em>ActionPlanner</em></a>) – Optional action planner object (obligatory for model based agents). Default = None.</p></li>
<li><p><strong>p_predicting_horizon</strong> (<em>int</em>) – Optional predicting horizon (obligatory for model based agents). Default = 0.</p></li>
<li><p><strong>p_controlling_horizon</strong> (<em>int</em>) – Optional controlling (obligatory for model based agents). Default = 0.</p></li>
<li><p><strong>p_planning_width</strong> (<em>int</em>) – Optional planning width (obligatory for model based agents). Default = 0.</p></li>
<li><p><strong>p_name</strong> (<em>str</em>) – Optional name of agent. Default = ‘’.</p></li>
<li><p><strong>p_id</strong> (<em>int</em>) – Optional unique agent id (especially important for multi-agent scenarios). Default = 0.</p></li>
<li><p><strong>p_ada</strong> (<em>bool</em>) – Boolean switch for adaptivity. Default = True.</p></li>
<li><p><strong>p_visualize</strong> (<em>bool</em>) – Boolean switch for env/agent visualisation. Default = False.</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class mlpro.bf.various.Log). Default = Log.C_LOG_ALL.</p></li>
<li><p><strong>p_mb_training_param</strong> (<em>dict</em>) – Optional parameters for internal policy training with environment model (see parameters of
class RLTraining). Hyperparameter tuning and data logging is not supported here. The suitable
scenario class is added internally.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_agents.Agent.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'Agent'</em><a class="headerlink" href="#mlpro.rl.models_agents.Agent.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_agents.Agent.C_NAME">
<code class="sig-name descname">C_NAME</code><em class="property"> = ''</em><a class="headerlink" href="#mlpro.rl.models_agents.Agent.C_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Agent.set_id">
<code class="sig-name descname">set_id</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_id</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Agent.set_id" title="Permalink to this definition">¶</a></dt>
<dd><p>The unique agent id will be defined while instantiation and can’t be changed anymore.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Agent.get_name">
<code class="sig-name descname">get_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Agent.get_name" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Agent.set_name">
<code class="sig-name descname">set_name</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_name</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Agent.set_name" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Agent.switch_logging">
<code class="sig-name descname">switch_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_logging</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Agent.switch_logging" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets new log level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_logging</strong> – Log level (constant C_LOG_LEVELS contains valid values)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Agent.switch_adaptivity">
<code class="sig-name descname">switch_adaptivity</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_ada</span><span class="p">:</span> <span class="n">bool</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Agent.switch_adaptivity" title="Permalink to this definition">¶</a></dt>
<dd><p>Switches adaption functionality on/off.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_ada</strong> (<em>bool</em>) – Boolean switch for adaptivity</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Agent.set_log_level">
<code class="sig-name descname">set_log_level</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_level</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Agent.set_log_level" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Agent.get_observation_space">
<code class="sig-name descname">get_observation_space</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a><a class="headerlink" href="#mlpro.rl.models_agents.Agent.get_observation_space" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Agent.get_action_space">
<code class="sig-name descname">get_action_space</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a><a class="headerlink" href="#mlpro.rl.models_agents.Agent.get_action_space" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Agent.set_random_seed">
<code class="sig-name descname">set_random_seed</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_seed</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Agent.set_random_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the internal random generator using the given seed.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Agent.compute_action">
<code class="sig-name descname">compute_action</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_state</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action">mlpro.bf.systems.Action</a><a class="headerlink" href="#mlpro.rl.models_agents.Agent.compute_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Default implementation of a single agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_state</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – State of the related environment.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>action</strong> – Action object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action">Action</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.Agent.clear_buffer">
<code class="sig-name descname">clear_buffer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.Agent.clear_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Clears internal buffer (if buffering is active).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_agents.MultiAgent">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_agents.</code><code class="sig-name descname">MultiAgent</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_name</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">p_ada</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">p_visualize</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#mlpro.rl.models_agents.Agent" title="mlpro.rl.models_agents.Agent"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_agents.Agent</span></code></a></p>
<p>Multi-Agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_name</strong> (<em>str</em>) – Name of agent. Default = ‘’.</p></li>
<li><p><strong>p_ada</strong> (<em>bool</em>) – Boolean switch for adaptivity. Default = True.</p></li>
<li><p><strong>p_visualize</strong> (<em>bool</em>) – Boolean switch for env/agent visualisation. Default = False.</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class Log). Default = Log.C_LOG_ALL.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_agents.MultiAgent.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'Multi-Agent'</em><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_agents.MultiAgent.C_NAME">
<code class="sig-name descname">C_NAME</code><em class="property"> = ''</em><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.C_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_agents.MultiAgent.C_SUFFIX">
<code class="sig-name descname">C_SUFFIX</code><em class="property"> = '.cfg'</em><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.C_SUFFIX" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.switch_logging">
<code class="sig-name descname">switch_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_logging</span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.switch_logging" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets new log level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_logging</strong> – Log level (constant C_LOG_LEVELS contains valid values)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.switch_adaptivity">
<code class="sig-name descname">switch_adaptivity</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_ada</span><span class="p">:</span> <span class="n">bool</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.switch_adaptivity" title="Permalink to this definition">¶</a></dt>
<dd><p>Switches adaption functionality on/off.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_ada</strong> (<em>bool</em>) – Boolean switch for adaptivity</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.set_log_level">
<code class="sig-name descname">set_log_level</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_level</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.set_log_level" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.get_filename">
<code class="sig-name descname">get_filename</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.get_filename" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_path</span></em>, <em class="sig-param"><span class="n">p_filename</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads content from the given path and file name. If file does not exist, it returns None.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Path that contains the file</strong> (<em>p_path</em>) – </p></li>
<li><p><strong>File name</strong> (<em>p_filename</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A loaded object, if file content was loaded successfully. None otherwise.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_path</span></em>, <em class="sig-param"><span class="n">p_filename</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves content to the given path and file name. If file name is None, a unique file name will
be generated by calling method generate_filename(). If it returns False then the saving method is failed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Path where file will be saved</strong> (<em>p_path</em>) – </p></li>
<li><p><strong>File name</strong> (<em>p_filename</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True, if file content was saved successfully. False otherwise.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.add_agent">
<code class="sig-name descname">add_agent</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_agent</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_agents.Agent" title="mlpro.rl.models_agents.Agent">mlpro.rl.models_agents.Agent</a></span></em>, <em class="sig-param"><span class="n">p_weight</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.add_agent" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds agent object to internal list of agents.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_agent</strong> (<a class="reference internal" href="#mlpro.rl.models_agents.Agent" title="mlpro.rl.models_agents.Agent"><em>Agent</em></a>) – Agent object to be added.</p></li>
<li><p><strong>p_weight</strong> (<em>float</em>) – Optional weight for the agent. Default = 1.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.get_agents">
<code class="sig-name descname">get_agents</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.get_agents" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.get_agent">
<code class="sig-name descname">get_agent</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_agent_id</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.get_agent" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns information of a single agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>agent_info</strong> – agent_info[0] is the agent object itself and agent_info[1] it’s weight</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.get_observation_space">
<code class="sig-name descname">get_observation_space</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.get_observation_space" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.get_action_space">
<code class="sig-name descname">get_action_space</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.get_action_space" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.set_random_seed">
<code class="sig-name descname">set_random_seed</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_seed</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.set_random_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the internal random generator using the given seed.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.compute_action">
<code class="sig-name descname">compute_action</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_state</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action">mlpro.bf.systems.Action</a><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.compute_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Default implementation of a single agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_state</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – State of the related environment.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>action</strong> – Action object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action">Action</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.clear_buffer">
<code class="sig-name descname">clear_buffer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.clear_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Clears internal buffer (if buffering is active).</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.init_plot">
<code class="sig-name descname">init_plot</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_figure</span><span class="p">:</span> <span class="n">matplotlib.figure.Figure</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_plot_settings</span><span class="p">:</span> <span class="n">list</span> <span class="o">=</span> <span class="default_value">Ellipsis</span></em>, <em class="sig-param"><span class="n">p_plot_depth</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_detail_level</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_step_rate</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">p_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.init_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Doesn’t support embedded plot of underlying agent hierarchy.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_agents.MultiAgent.update_plot">
<code class="sig-name descname">update_plot</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">p_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_agents.MultiAgent.update_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the plot.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>**p_kwargs</strong> – Implementation-specific plot data and/or parameters.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="scenarios-training-and-tuning">
<h2>Scenarios, Training and Tuning<a class="headerlink" href="#scenarios-training-and-tuning" title="Permalink to this headline">¶</a></h2>
<img alt="../../../../../_images/MLPro-RL-Train_class_diagram.drawio.png" src="../../../../../_images/MLPro-RL-Train_class_diagram.drawio.png" />
<span class="target" id="module-mlpro.rl.models_train"></span><p>Ver. 1.8.4 (2023-02-02)</p>
<p>This module provides model classes to define and run rl scenarios and to train agents inside them.</p>
<dl class="py class">
<dt id="mlpro.rl.models_train.RLDataStoring">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_train.</code><code class="sig-name descname">RLDataStoring</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_space</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.Set" title="mlpro.bf.math.basics.Set">mlpro.bf.math.basics.Set</a></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoring" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="mlpro.bf.html#mlpro.bf.data.DataStoring" title="mlpro.bf.data.DataStoring"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.data.DataStoring</span></code></a></p>
<p>Derivative of basic class DataStoring that is specialized to store episodic training data in the
context of reinforcement learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_space</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.Set" title="mlpro.bf.math.basics.Set"><em>Set</em></a>) – Space object that provides dimensional information for raw data. If None, a training header
data object will be instantiated.</p>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoring.C_VAR0">
<code class="sig-name descname">C_VAR0</code><em class="property"> = 'Episode ID'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoring.C_VAR0" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoring.C_VAR_CYCLE">
<code class="sig-name descname">C_VAR_CYCLE</code><em class="property"> = 'Cycle'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoring.C_VAR_CYCLE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoring.C_VAR_DAY">
<code class="sig-name descname">C_VAR_DAY</code><em class="property"> = 'Day'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoring.C_VAR_DAY" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoring.C_VAR_SEC">
<code class="sig-name descname">C_VAR_SEC</code><em class="property"> = 'Second'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoring.C_VAR_SEC" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoring.C_VAR_MICROSEC">
<code class="sig-name descname">C_VAR_MICROSEC</code><em class="property"> = 'Microsecond'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoring.C_VAR_MICROSEC" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLDataStoring.get_variables">
<code class="sig-name descname">get_variables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoring.get_variables" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLDataStoring.get_space">
<code class="sig-name descname">get_space</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoring.get_space" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLDataStoring.add_episode">
<code class="sig-name descname">add_episode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_episode_id</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoring.add_episode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLDataStoring.memorize_row">
<code class="sig-name descname">memorize_row</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_cycle_id</span></em>, <em class="sig-param"><span class="n">p_tstamp</span><span class="p">:</span> <span class="n">datetime.timedelta</span></em>, <em class="sig-param"><span class="n">p_data</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoring.memorize_row" title="Permalink to this definition">¶</a></dt>
<dd><p>Memorizes an episodic data row.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Cycle id</strong> (<em>p_cycle_id</em>) – </p></li>
<li><p><strong>Time stamp</strong> (<em>p_tstamp</em>) – </p></li>
<li><p><strong>Data that meet the dimensionality of the related space</strong> (<em>p_data</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_train.RLDataStoringEval">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_train.</code><code class="sig-name descname">RLDataStoringEval</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_space</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.Set" title="mlpro.bf.math.basics.Set">mlpro.bf.math.basics.Set</a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="mlpro.bf.html#mlpro.bf.data.DataStoring" title="mlpro.bf.data.DataStoring"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.data.DataStoring</span></code></a></p>
<p>Derivative of basic class DataStoring that is specialized to store evaluation data of a training
in the context of reinforcement learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_space</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.math.basics.Set" title="mlpro.bf.math.basics.Set"><em>Set</em></a>) – Set object that provides dimensional information for raw data. If None a training header data object will</p></li>
<li><p><strong>instantiated.</strong> (<em>be</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoringEval.C_VAR0">
<code class="sig-name descname">C_VAR0</code><em class="property"> = 'Evaluation ID'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.C_VAR0" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoringEval.C_VAR_SCORE">
<code class="sig-name descname">C_VAR_SCORE</code><em class="property"> = 'Score'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.C_VAR_SCORE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoringEval.C_VAR_SCORE_MA">
<code class="sig-name descname">C_VAR_SCORE_MA</code><em class="property"> = 'Score(MA)'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.C_VAR_SCORE_MA" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoringEval.C_VAR_SCORE_UNTIL_STAG">
<code class="sig-name descname">C_VAR_SCORE_UNTIL_STAG</code><em class="property"> = 'Score until Stagnation'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.C_VAR_SCORE_UNTIL_STAG" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoringEval.C_VAR_SCORE_MA_UNTIL_STAG">
<code class="sig-name descname">C_VAR_SCORE_MA_UNTIL_STAG</code><em class="property"> = 'Score(MA) until Stagnation'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.C_VAR_SCORE_MA_UNTIL_STAG" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoringEval.C_VAR_NUM_CYCLES">
<code class="sig-name descname">C_VAR_NUM_CYCLES</code><em class="property"> = 'Cycles'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.C_VAR_NUM_CYCLES" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoringEval.C_VAR_NUM_SUCCESS">
<code class="sig-name descname">C_VAR_NUM_SUCCESS</code><em class="property"> = 'Successes'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.C_VAR_NUM_SUCCESS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoringEval.C_VAR_NUM_BROKEN">
<code class="sig-name descname">C_VAR_NUM_BROKEN</code><em class="property"> = 'Crashes'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.C_VAR_NUM_BROKEN" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoringEval.C_VAR_NUM_LIMIT">
<code class="sig-name descname">C_VAR_NUM_LIMIT</code><em class="property"> = 'Timeouts'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.C_VAR_NUM_LIMIT" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLDataStoringEval.C_VAR_NUM_ADAPT">
<code class="sig-name descname">C_VAR_NUM_ADAPT</code><em class="property"> = 'Adaptations'</em><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.C_VAR_NUM_ADAPT" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLDataStoringEval.get_variables">
<code class="sig-name descname">get_variables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.get_variables" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLDataStoringEval.get_space">
<code class="sig-name descname">get_space</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.get_space" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLDataStoringEval.add_evaluation">
<code class="sig-name descname">add_evaluation</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_evaluation_id</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.add_evaluation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLDataStoringEval.memorize_row">
<code class="sig-name descname">memorize_row</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_score</span></em>, <em class="sig-param"><span class="n">p_score_ma</span></em>, <em class="sig-param"><span class="n">p_num_limit</span></em>, <em class="sig-param"><span class="n">p_num_cycles</span></em>, <em class="sig-param"><span class="n">p_num_success</span></em>, <em class="sig-param"><span class="n">p_num_broken</span></em>, <em class="sig-param"><span class="n">p_num_adaptations</span></em>, <em class="sig-param"><span class="n">p_reward</span></em>, <em class="sig-param"><span class="n">p_score_until_stag</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_score_ma_until_stag</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLDataStoringEval.memorize_row" title="Permalink to this definition">¶</a></dt>
<dd><p>Memorizes an evaluation data row.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_score</strong> (<em>float</em>) – Score value of current evaluation.</p></li>
<li><p><strong>p_score_ma</strong> (<em>float</em>) – Moving average score value.</p></li>
<li><p><strong>p_num_limit</strong> (<em>int</em>) – Number of episodes in timeout.</p></li>
<li><p><strong>p_num_cycles</strong> (<em>int</em>) – Number of evaluation cycles.</p></li>
<li><p><strong>p_num_success</strong> (<em>int</em>) – Number of states that were labeled as successfully.</p></li>
<li><p><strong>p_num_broken</strong> (<em>int</em>) – Number of states that were labeled as broken.</p></li>
<li><p><strong>p_num_adaptations</strong> (<em>int</em>) – Number of adaptations in the last training period.</p></li>
<li><p><strong>p_reward</strong> (<em>list</em>) – Episode Reward</p></li>
<li><p><strong>p_score_until_stag</strong> (<em>float</em>) – Optional score value of current evaluation until first stagnation. Default = None.</p></li>
<li><p><strong>p_score_ma_until_stag</strong> (<em>float</em>) – Optional moving average score value until first stagnation. Default = None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_train.RLScenario">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_train.</code><code class="sig-name descname">RLScenario</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_mode</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_ada</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">p_cycle_limit</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_visualize</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLScenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.ml.basics.Scenario</span></code></p>
<p>Template class for an RL scenario consisting of an environment and an agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_mode</strong> – Operation mode. See bf.ops.Mode.C_VALID_MODES for valid values. Default = Mode.C_MODE_SIM.</p></li>
<li><p><strong>p_ada</strong> (<em>bool</em>) – Boolean switch for adaptivitiy. Default = True.</p></li>
<li><p><strong>p_cycle_limit</strong> (<em>int</em>) – Maximum number of cycles (0=no limit, -1=get from env). Default = 0.</p></li>
<li><p><strong>p_visualize</strong> (<em>bool</em>) – Boolean switch for env/agent visualisation. Default = False.</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class mlpro.bf.various.Log). Default = Log.C_LOG_WE.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLScenario.C_TYPE">
<code class="sig-name descname">C_TYPE</code><a class="headerlink" href="#mlpro.rl.models_train.RLScenario.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd><p>Constant class type for logging: ‘RL-Scenario’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLScenario.C_NAME">
<code class="sig-name descname">C_NAME</code><a class="headerlink" href="#mlpro.rl.models_train.RLScenario.C_NAME" title="Permalink to this definition">¶</a></dt>
<dd><p>Constant custom name for logging. To be set in own child class.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="id1">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'RL-Scenario'</em><a class="headerlink" href="#id1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="id2">
<code class="sig-name descname">C_NAME</code><em class="property"> = '????'</em><a class="headerlink" href="#id2" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLScenario.switch_logging">
<code class="sig-name descname">switch_logging</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_logging</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLScenario.switch_logging" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets new log level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_logging</strong> – Log level (constant C_LOG_LEVELS contains valid values)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLScenario.init_plot">
<code class="sig-name descname">init_plot</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_figure</span><span class="p">:</span> <span class="n">matplotlib.figure.Figure</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_plot_settings</span><span class="p">:</span> <span class="n"><a class="reference internal" href="mlpro.bf.html#mlpro.bf.plot.PlotSettings" title="mlpro.bf.plot.PlotSettings">mlpro.bf.plot.PlotSettings</a></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLScenario.init_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes the plot functionalities of the class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_figure</strong> (<em>Matplotlib.figure.Figure</em><em>, </em><em>optional</em>) – Optional MatPlotLib host figure, where the plot shall be embedded. The default is None.</p></li>
<li><p><strong>p_plot_settings</strong> (<a class="reference internal" href="mlpro.bf.html#mlpro.bf.plot.PlotSettings" title="mlpro.bf.plot.PlotSettings"><em>PlotSettings</em></a>) – Optional plot settings. If None, the default view is plotted (see attribute C_PLOT_DEFAULT_VIEW).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLScenario.update_plot">
<code class="sig-name descname">update_plot</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">p_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLScenario.update_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the plot.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>**p_kwargs</strong> – Implementation-specific plot data and/or parameters.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLScenario.get_latency">
<code class="sig-name descname">get_latency</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; datetime.timedelta<a class="headerlink" href="#mlpro.rl.models_train.RLScenario.get_latency" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the latency of the scenario. To be implemented in child class.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLScenario.get_agent">
<code class="sig-name descname">get_agent</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLScenario.get_agent" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLScenario.get_env">
<code class="sig-name descname">get_env</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLScenario.get_env" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLScenario.connect_data_logger">
<code class="sig-name descname">connect_data_logger</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_ds_states</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_train.RLDataStoring" title="mlpro.rl.models_train.RLDataStoring">mlpro.rl.models_train.RLDataStoring</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_ds_actions</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_train.RLDataStoring" title="mlpro.rl.models_train.RLDataStoring">mlpro.rl.models_train.RLDataStoring</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_ds_rewards</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_train.RLDataStoring" title="mlpro.rl.models_train.RLDataStoring">mlpro.rl.models_train.RLDataStoring</a></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLScenario.connect_data_logger" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_train.RLTrainingResults">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_train.</code><code class="sig-name descname">RLTrainingResults</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_scenario</span><span class="p">:</span> <span class="n"><a class="reference internal" href="#mlpro.rl.models_train.RLScenario" title="mlpro.rl.models_train.RLScenario">mlpro.rl.models_train.RLScenario</a></span></em>, <em class="sig-param"><span class="n">p_run</span></em>, <em class="sig-param"><span class="n">p_cycle_id</span></em>, <em class="sig-param"><span class="n">p_path</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">'W'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLTrainingResults" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.ml.basics.TrainingResults</span></code></p>
<p>Results of a RL training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_scenario</strong> (<a class="reference internal" href="#mlpro.rl.models_train.RLScenario" title="mlpro.rl.models_train.RLScenario"><em>RLScenario</em></a>) – Related reinforcement learning scenario.</p></li>
<li><p><strong>p_run</strong> (<em>int</em>) – Run id.</p></li>
<li><p><strong>p_cycle_id</strong> (<em>int</em>) – Id of first cycle of this run.</p></li>
<li><p><strong>p_path</strong> (<em>str</em>) – Optional destination path to store the results.</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class Log). Default: Log.C_LOG_ALL</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLTrainingResults.C_NAME">
<code class="sig-name descname">C_NAME</code><em class="property"> = 'RL'</em><a class="headerlink" href="#mlpro.rl.models_train.RLTrainingResults.C_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLTrainingResults.C_FNAME_EVAL">
<code class="sig-name descname">C_FNAME_EVAL</code><em class="property"> = 'evaluation'</em><a class="headerlink" href="#mlpro.rl.models_train.RLTrainingResults.C_FNAME_EVAL" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLTrainingResults.C_FNAME_ENV_STATES">
<code class="sig-name descname">C_FNAME_ENV_STATES</code><em class="property"> = 'env_states'</em><a class="headerlink" href="#mlpro.rl.models_train.RLTrainingResults.C_FNAME_ENV_STATES" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLTrainingResults.C_FNAME_AGENT_ACTIONS">
<code class="sig-name descname">C_FNAME_AGENT_ACTIONS</code><em class="property"> = 'agent_actions'</em><a class="headerlink" href="#mlpro.rl.models_train.RLTrainingResults.C_FNAME_AGENT_ACTIONS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLTrainingResults.C_FNAME_ENV_REWARDS">
<code class="sig-name descname">C_FNAME_ENV_REWARDS</code><em class="property"> = 'env_rewards'</em><a class="headerlink" href="#mlpro.rl.models_train.RLTrainingResults.C_FNAME_ENV_REWARDS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLTrainingResults.C_CPAR_NUM_EPI">
<code class="sig-name descname">C_CPAR_NUM_EPI</code><em class="property"> = 'Training Episodes'</em><a class="headerlink" href="#mlpro.rl.models_train.RLTrainingResults.C_CPAR_NUM_EPI" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLTrainingResults.C_CPAR_NUM_EVAL">
<code class="sig-name descname">C_CPAR_NUM_EVAL</code><em class="property"> = 'Evaluations'</em><a class="headerlink" href="#mlpro.rl.models_train.RLTrainingResults.C_CPAR_NUM_EVAL" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLTrainingResults.close">
<code class="sig-name descname">close</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLTrainingResults.close" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.rl.models_train.RLTrainingResults.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_path</span></em>, <em class="sig-param"><span class="n">p_filename</span><span class="o">=</span><span class="default_value">'summary.csv'</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.rl.models_train.RLTrainingResults.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves a training summary in the given path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_path</strong> (<em>str</em>) – Destination folder</p></li>
<li><p><strong>p_filename</strong> (<em>string</em>) – Name of summary file. Default = ‘summary.csv’</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>success</strong> – True, if summary file was created successfully. False otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.rl.models_train.RLTraining">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.rl.models_train.</code><code class="sig-name descname">RLTraining</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">p_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.rl.models_train.RLTraining" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.bf.ml.basics.Training</span></code></p>
<p>This class performs an episodic training on a (multi-)agent in a given environment. Both are
expected as parts of a reinforcement learning scenario (see class RLScenario for more details).
The class optionally collects all relevant data like environment states and rewards or agents
actions. Furthermore, overarching training data will be collected.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_scenario_cls</strong> – Name of RL scenario class, compatible to/inherited from class RLScenario.</p></li>
<li><p><strong>p_cycle_limit</strong> (<em>int</em>) – Maximum number of training cycles (0=no limit). Default = 0.</p></li>
<li><p><strong>p_cycles_per_epi_limit</strong> (<em>int</em>) – Optional limit of cycles per episode (0=no limit, -1=get environment limit). Default = -1.</p></li>
<li><p><strong>p_adaptation_limit</strong> (<em>int</em>) – Maximum number of adaptations (0=no limit). Default = 0.</p></li>
<li><p><strong>p_eval_frequency</strong> (<em>int</em>) – Optional evaluation frequency (0=no evaluation). Default = 0.</p></li>
<li><p><strong>p_eval_grp_size</strong> (<em>int</em>) – Number of evaluation episodes (eval group). Default = 0.</p></li>
<li><p><strong>p_score_ma_horizon</strong> (<em>int</em>) – Horizon length for moving average score computation. Default = 5.</p></li>
<li><p><strong>p_stagnation_limit</strong> (<em>int</em>) – Optional limit of consecutive evaluations without training progress. Base is the moving average
score. Default = 0.</p></li>
<li><p><strong>p_stagnation_entry</strong> (<em>int</em>) – Optional number of evaluations before the stagnation detection starts. Default = 0.</p></li>
<li><p><strong>p_end_at_stagnation</strong> (<em>bool</em>) – If True, the training ends when stagnation has beed detected. Default = True.</p></li>
<li><p><strong>p_hpt</strong> (<em>HyperParamTuner</em>) – Optional hyperparameter tuner (see class mlpro.bf.ml.HyperParamTuner). Default = None.</p></li>
<li><p><strong>p_hpt_trials</strong> (<em>int</em>) – Optional number of hyperparameter tuning trials. Default = 0. Must be &gt; 0 if p_hpt is supplied.</p></li>
<li><p><strong>p_path</strong> (<em>str</em>) – Optional destination path to store training data. Default = None.</p></li>
<li><p><strong>p_collect_states</strong> (<em>bool</em>) – If True, the environment states will be collected. Default = True.</p></li>
<li><p><strong>p_collect_actions</strong> (<em>bool</em>) – If True, the agent actions will be collected. Default = True.</p></li>
<li><p><strong>p_collect_rewards</strong> (<em>bool</em>) – If True, the environment reward will be collected. Default = True.</p></li>
<li><p><strong>p_collect_eval</strong> (<em>bool</em>) – If True, global evaluation data will be collected. Default = True.</p></li>
<li><p><strong>p_visualize</strong> (<em>bool</em>) – Boolean switch for env/agent visualisation. Default = False.</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class mlpro.bf.various.Log). Default = Log.C_LOG_WE.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLTraining.C_NAME">
<code class="sig-name descname">C_NAME</code><em class="property"> = 'RL'</em><a class="headerlink" href="#mlpro.rl.models_train.RLTraining.C_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.rl.models_train.RLTraining.C_CLS_RESULTS">
<code class="sig-name descname">C_CLS_RESULTS</code><a class="headerlink" href="#mlpro.rl.models_train.RLTraining.C_CLS_RESULTS" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#mlpro.rl.models_train.RLTrainingResults" title="mlpro.rl.models_train.RLTrainingResults"><code class="xref py py-class docutils literal notranslate"><span class="pre">RLTrainingResults</span></code></a></p>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mlpro.sl.html" class="btn btn-neutral float-left" title="Supervised Learning" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mlpro.gt.html" class="btn btn-neutral float-right" title="Game Theory" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022 South Westphalia University of Applied Sciences, Germany.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>