<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>OpenAI Gym &mdash; MLPro Documentations 1.0.0 documentation</title><link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/custom.css" type="text/css" /><link rel="shortcut icon" href="../../../../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script src="../../../../../_static/language_data.js"></script>
        <script src="../../../../../_static/clipboard.min.js"></script>
        <script src="../../../../../_static/copybutton.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
    <link rel="next" title="OpenML" href="openml.html" />
    <link rel="prev" title="Hyperopt" href="hyperopt.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../index.html" class="icon icon-home"> MLPro Documentations<img src="../../../../../_static/logo_mlpro.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Welcome to MLPro</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_welcome/sub/01_introduction.html">5. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_welcome/sub/02_getting_started.html">6. Getting Started</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic Functions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_basic_functions/mlpro_bf/main.html">7. MLPro-BF - Basic Functions</a></li>
</ul>
<p class="caption"><span class="caption-text">Machine Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_machine_learning/mlpro_sl/main.html">8. MLPro-SL - Supervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_machine_learning/mlpro_rl/main.html">9. MLPro-RL - Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_machine_learning/mlpro_gt/main.html">10. MLPro-GT - Game Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_machine_learning/mlpro_oa/main.html">11. MLPro-OA - Online Adaptivity</a></li>
</ul>
<p class="caption"><span class="caption-text">Appendices</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../appendix1/main.html">A1 - Example Pool</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../main.html">A2 - API Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../01_mlpro.core.html">Core Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02_mlpro.pool.html">Pool Objects</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../03_mlpro.wrappers.html">Wrappers</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="hyperopt.html">Hyperopt</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">OpenAI Gym</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#cross-references">Cross References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="openml.html">OpenML</a></li>
<li class="toctree-l3"><a class="reference internal" href="optuna.html">Optuna</a></li>
<li class="toctree-l3"><a class="reference internal" href="pettingzoo.html">PettingZoo</a></li>
<li class="toctree-l3"><a class="reference internal" href="river.html">River</a></li>
<li class="toctree-l3"><a class="reference internal" href="sb3.html">Stable Baslines3</a></li>
<li class="toctree-l3"><a class="reference internal" href="sklearn.html">Scikit-learn</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../appendix3/main.html">A3 - Project MLPro</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">MLPro Documentations</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../main.html">A2 - API Reference</a> &raquo;</li>
          <li><a href="../03_mlpro.wrappers.html">Wrappers</a> &raquo;</li>
      <li>OpenAI Gym</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/fhswf/MLPro/blob/main/doc/docs/content/04_appendices/appendix2/sub/wrappers/openai_gym.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="module-mlpro.wrappers.openai_gym">
<span id="openai-gym"></span><h1>OpenAI Gym<a class="headerlink" href="#module-mlpro.wrappers.openai_gym" title="Permalink to this headline">¶</a></h1>
<p>Ver. 1.4.8 (2023-01-14)</p>
<p>This module provides wrapper classes for OpenAI Gym environments.</p>
<p>See also: <a class="reference external" href="https://pypi.org/project/gym">https://pypi.org/project/gym</a></p>
<dl class="py class">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.wrappers.openai_gym.</code><code class="sig-name descname">WrEnvGYM2MLPro</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_gym_env</span></em>, <em class="sig-param"><span class="n">p_state_space</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_action_space</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_visualize</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.wrappers.models.Wrapper</span></code>, <a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_env.Environment" title="mlpro.rl.models_env.Environment"><code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.rl.models_env.Environment</span></code></a></p>
<p>This class is a ready to use wrapper class for OpenAI Gym environments.
Objects of this type can be treated as an environment object. Encapsulated
gym environment must be compatible to class gym.Env.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_gym_env</strong> (<em>Env</em>) – Gym environment object</p></li>
<li><p><strong>p_state_space</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace"><em>MSpace</em></a>) – Optional external state space object that meets the state space of the Gym environment</p></li>
<li><p><strong>p_action_space</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace"><em>MSpace</em></a>) – Optional external action space object that meets the action space of the Gym environment</p></li>
<li><p><strong>p_visualize</strong> (<em>bool</em>) – Boolean switch for env/agent visualisation. Default = True.</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class Log). Default = Log.C_LOG_ALL.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'Wrapper OpenAI Gym -&gt; MLPro'</em><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.C_WRAPPED_PACKAGE">
<code class="sig-name descname">C_WRAPPED_PACKAGE</code><em class="property"> = 'gym'</em><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.C_WRAPPED_PACKAGE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.C_PLOT_ACTIVE">
<code class="sig-name descname">C_PLOT_ACTIVE</code><em class="property">: bool</em><em class="property"> = True</em><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.C_PLOT_ACTIVE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.recognize_space">
<em class="property">static </em><code class="sig-name descname">recognize_space</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_gym_space</span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.basics.ESpace" title="mlpro.bf.math.basics.ESpace">mlpro.bf.math.basics.ESpace</a><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.recognize_space" title="Permalink to this definition">¶</a></dt>
<dd><p>Detecting a gym space and transform it to MLPro space. Hence, the transformed space can be
directly compatible in MLPro.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_gym_space</strong> (container spaces (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>)) – Spaces are crucially used in Gym to define the format of valid actions and observations.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>space</strong> – MLPro compatible space.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.basics.ESpace" title="mlpro.bf.math.basics.ESpace">ESpace</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.setup_spaces">
<em class="property">static </em><code class="sig-name descname">setup_spaces</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.setup_spaces" title="Permalink to this definition">¶</a></dt>
<dd><p>To setup spaces. To be optionally defined by the users.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.simulate_reaction">
<code class="sig-name descname">simulate_reaction</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_state</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span></em>, <em class="sig-param"><span class="n">p_action</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action">mlpro.bf.systems.Action</a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.simulate_reaction" title="Permalink to this definition">¶</a></dt>
<dd><p>Simulates a state transition based on a state and an action. The simulation step itself is
carried out either by an internal custom implementation in method _simulate_reaction() or
by an embedded adaptive function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_state</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – Current state.</p></li>
<li><p><strong>p_action</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.Action" title="mlpro.bf.systems.Action"><em>Action</em></a>) – Action.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>state</strong> – Subsequent state after transition</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">State</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_reward">
<code class="sig-name descname">compute_reward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_state_old</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_state_new</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_env.Reward" title="mlpro.rl.models_env.Reward">mlpro.rl.models_env.Reward</a><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_reward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a reward for the state transition, given by two successive states. The reward
computation itself is carried out either by a custom implementation in method
_compute_reward() or by an embedded adaptive function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_state_old</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – Optional state before transition. If None the internal previous state of the environment
is used.</p></li>
<li><p><strong>p_state_new</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – Optional tate after transition. If None the internal current state of the environment
is used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Reward object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_env.Reward" title="mlpro.rl.models_env.Reward">Reward</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_success">
<code class="sig-name descname">compute_success</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_state</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_success" title="Permalink to this definition">¶</a></dt>
<dd><p>Assesses the given state whether it is a ‘success’ state. Assessment is carried out either by
a custom implementation in method _compute_success() or by an embedded adaptive function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_state</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – State to be assessed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True, if the given state is a ‘success’ state. False otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_broken">
<code class="sig-name descname">compute_broken</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_state</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State">mlpro.bf.systems.State</a></span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.compute_broken" title="Permalink to this definition">¶</a></dt>
<dd><p>Assesses the given state whether it is a ‘broken’ state. Assessment is carried out either by
a custom implementation in method _compute_broken() or by an embedded adaptive function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_state</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.systems.State" title="mlpro.bf.systems.State"><em>State</em></a>) – State to be assessed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True, if the given state is a ‘broken’ state. False otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.init_plot">
<code class="sig-name descname">init_plot</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_figure</span><span class="p">:</span> <span class="n">matplotlib.figure.Figure</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_plot_settings</span><span class="p">:</span> <span class="n">list</span> <span class="o">=</span> <span class="default_value">Ellipsis</span></em>, <em class="sig-param"><span class="n">p_plot_depth</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_detail_level</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p_step_rate</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">p_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.init_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes the plot functionalities of the class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_figure</strong> (<em>Matplotlib.figure.Figure</em><em>, </em><em>optional</em>) – Optional MatPlotLib host figure, where the plot shall be embedded. The default is None.</p></li>
<li><p><strong>p_plot_settings</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.plot.PlotSettings" title="mlpro.bf.plot.PlotSettings"><em>PlotSettings</em></a>) – Optional plot settings. If None, the default view is plotted (see attribute C_PLOT_DEFAULT_VIEW).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.update_plot">
<code class="sig-name descname">update_plot</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">p_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.update_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Updating the actual plot, deployed by render functionality from OpenAI Gym.</p>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.get_cycle_limit">
<code class="sig-name descname">get_cycle_limit</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvGYM2MLPro.get_cycle_limit" title="Permalink to this definition">¶</a></dt>
<dd><p>To obtain the information regarding the cycle limit from the environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the number of the cycle limit.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM">
<em class="property">class </em><code class="sig-prename descclassname">mlpro.wrappers.openai_gym.</code><code class="sig-name descname">WrEnvMLPro2GYM</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_mlpro_env</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_env.Environment" title="mlpro.rl.models_env.Environment">mlpro.rl.models_env.Environment</a></span></em>, <em class="sig-param"><span class="n">p_state_space</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_action_space</span><span class="p">:</span> <span class="n"><a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace">mlpro.bf.math.basics.MSpace</a></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_new_step_api</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">p_render_mode</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p_logging</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mlpro.wrappers.models.Wrapper</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">gym.core.Env</span></code></p>
<p>This class is a ready to use wrapper class for MLPro to OpenAI Gym environments.
Objects of this type can be treated as an gym.Env object. Encapsulated
MLPro environment must be compatible to class Environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p_mlpro_env</strong> (<a class="reference internal" href="../core/mlpro.rl.html#mlpro.rl.models_env.Environment" title="mlpro.rl.models_env.Environment"><em>Environment</em></a>) – MLPro’s Environment object</p></li>
<li><p><strong>p_state_space</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace"><em>MSpace</em></a>) – Optional external state space object that meets the state space of the MLPro environment</p></li>
<li><p><strong>p_action_space</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.basics.MSpace" title="mlpro.bf.math.basics.MSpace"><em>MSpace</em></a>) – Optional external action space object that meets the state space of the MLPro environment</p></li>
<li><p><strong>p_new_step_api</strong> (<em>bool</em>) – If true, the user assures that the environment compatible to Gym version 0.25.0 or above.
Otherwise, it is false. Default = False.</p></li>
<li><p><strong>p_render_mde</strong> (<em>str</em>) – To allow the user to specify render_mode handled by the environment, for instance,
‘human’, ‘rgb_array’, and ‘single_rgb_array’. Default = None.</p></li>
<li><p><strong>p_logging</strong> – Log level (see constants of class Log). Default = Log.C_LOG_ALL.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.C_TYPE">
<code class="sig-name descname">C_TYPE</code><em class="property"> = 'Wrapper MLPro -&gt; OpenAI Gym'</em><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.C_TYPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.C_WRAPPED_PACKAGE">
<code class="sig-name descname">C_WRAPPED_PACKAGE</code><em class="property"> = 'gym'</em><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.C_WRAPPED_PACKAGE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.metadata">
<code class="sig-name descname">metadata</code><em class="property"> = {'render.modes': ['human']}</em><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.metadata" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.recognize_space">
<em class="property">static </em><code class="sig-name descname">recognize_space</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p_mlpro_space</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.recognize_space" title="Permalink to this definition">¶</a></dt>
<dd><p>Detecting a MLPro space and transform it to gym space. Hence, the transformed space can be
directly compatible in gym.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p_mlpro_space</strong> (<a class="reference internal" href="../core/mlpro.bf.html#mlpro.bf.math.basics.ESpace" title="mlpro.bf.math.basics.ESpace"><em>ESpace</em></a>) – MLPro compatible space.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>space</strong> – Spaces are crucially used in Gym to define the format of valid actions and observations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>container spaces (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">action</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.step" title="Permalink to this definition">¶</a></dt>
<dd><p>To execute one time step within the environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>action</strong> (<em>ActType</em>) – an action provided by the agent.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>obs</strong> (<em>object</em>) – This will be an element of the environment’s <code class="xref py py-attr docutils literal notranslate"><span class="pre">observation_space</span></code>.
This may, for instance, be a numpy array containing the positions and velocities of certain objects.</p></li>
<li><p><strong>reward.get_overall_reward()</strong> (<em>float</em>) – The amount of reward returned as a result of taking the action.</p></li>
<li><p><strong>terminated</strong> (<em>bool</em>) – whether a <cite>terminal state</cite> (as defined under the MDP of the task) is reached.
In this case further step() calls could return undefined results.</p></li>
<li><p><strong>truncated</strong> (<em>bool</em>) – whether a truncation condition outside the scope of the MDP is satisfied.
Typically a timelimit, but could also be used to indicate agent physically going out of bounds.
Can be used to end the episode prematurely before a <cite>terminal state</cite> is reached.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – It contains auxiliary diagnostic information (helpful for debugging, learning, and logging).
This might, for instance, contain: metrics that describe the agent’s performance state, variables that are
hidden from observations, or individual reward terms that are combined to produce the total reward.
It also can contain information that distinguishes truncation and termination, however this is deprecated in favour
of returning two booleans, and will be removed in a future version.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.reset_new">
<code class="sig-name descname">reset_new</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">seed</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">return_info</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">options</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.reset_new" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the environment to an initial state and returns the initial observation.
This is for new gym version.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed</strong> (<em>int</em><em>, </em><em>optional</em>) – The seed that is used to initialize the environment’s PRNG.
If the environment does not already have a PRNG and <code class="docutils literal notranslate"><span class="pre">seed=None</span></code> (the default option) is passed,
a seed will be chosen from some source of entropy (e.g. timestamp or /dev/urandom).
However, if the environment already has a PRNG and <code class="docutils literal notranslate"><span class="pre">seed=None</span></code> is passed, the PRNG will <em>not</em> be reset.
If you pass an integer, the PRNG will be reset even if it already exists.
Usually, you want to pass an integer <em>right after the environment has been initialized and then never again</em>.
Please refer to the minimal example above to see this paradigm in action.
The default is None.</p></li>
<li><p><strong>return_info</strong> (<em>bool</em>) – If true, return additional information along with initial observation.
This info should be analogous to the info returned in <a class="reference internal" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.step" title="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code></a>.
The default is False.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>, </em><em>optional</em>) – Additional information to specify how the environment is reset (optional,
depending on the specific environment). The default is None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>obs</strong> (<em>object</em>) – This will be an element of the environment’s <code class="xref py py-attr docutils literal notranslate"><span class="pre">observation_space</span></code>.
This may, for instance, be a numpy array containing the positions and velocities of certain objects.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – It contains auxiliary diagnostic information (helpful for debugging, learning, and logging).
This might, for instance, contain: metrics that describe the agent’s performance state, variables that are
hidden from observations, or individual reward terms that are combined to produce the total reward.
It also can contain information that distinguishes truncation and termination, however this is deprecated in favour
of returning two booleans, and will be removed in a future version.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.reset_old">
<code class="sig-name descname">reset_old</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.reset_old" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the environment to an initial state and returns the initial observation.
This is for old gym version.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed</strong> (<em>int</em><em>, </em><em>optional</em>) – The seed that is used to initialize the environment’s PRNG.
If the environment does not already have a PRNG and <code class="docutils literal notranslate"><span class="pre">seed=None</span></code> (the default option) is passed,
a seed will be chosen from some source of entropy (e.g. timestamp or /dev/urandom).
However, if the environment already has a PRNG and <code class="docutils literal notranslate"><span class="pre">seed=None</span></code> is passed, the PRNG will <em>not</em> be reset.
If you pass an integer, the PRNG will be reset even if it already exists.
Usually, you want to pass an integer <em>right after the environment has been initialized and then never again</em>.
Please refer to the minimal example above to see this paradigm in action.
The default is None.</p></li>
<li><p><strong>return_info</strong> (<em>bool</em>) – If true, return additional information along with initial observation.
This info should be analogous to the info returned in <a class="reference internal" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.step" title="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code></a>.
The default is False.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>, </em><em>optional</em>) – Additional information to specify how the environment is reset (optional,
depending on the specific environment). The default is None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>obs</strong> (<em>object</em>) – This will be an element of the environment’s <code class="xref py py-attr docutils literal notranslate"><span class="pre">observation_space</span></code>.
This may, for instance, be a numpy array containing the positions and velocities of certain objects.</p></li>
<li><p><strong>info</strong> (<em>dict</em>) – It contains auxiliary diagnostic information (helpful for debugging, learning, and logging).
This might, for instance, contain: metrics that describe the agent’s performance state, variables that are
hidden from observations, or individual reward terms that are combined to produce the total reward.
It also can contain information that distinguishes truncation and termination, however this is deprecated in favour
of returning two booleans, and will be removed in a future version.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.render">
<code class="sig-name descname">render</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mode</span><span class="o">=</span><span class="default_value">'human'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.render" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the render frames as specified by render_mode attribute during initialization of the environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>str</em><em>, </em><em>optional</em>) – To allow the user to specify render_mode handled by the environment, for instance,
‘human’, ‘rgb_array’, and ‘single_rgb_array’. The default is ‘human’.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Rendering is successful or not.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.close">
<code class="sig-name descname">close</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.close" title="Permalink to this definition">¶</a></dt>
<dd><p>Override close in your subclass to perform any necessary cleanup.
Environments will automatically <a class="reference internal" href="#mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.close" title="mlpro.wrappers.openai_gym.WrEnvMLPro2GYM.close"><code class="xref py py-meth docutils literal notranslate"><span class="pre">close()</span></code></a> themselves when garbage collected or when the program exits.</p>
</dd></dl>

</dd></dl>

<div class="section" id="cross-references">
<h2>Cross References<a class="headerlink" href="#cross-references" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p><span class="xref std std-ref">Howto RL-WP-001: MLPro to OpenAI Gym</span></p></li>
<li><p><a class="reference internal" href="../../../appendix1/sub/rl/agent/howto.rl.agent.001.html#howto-agent-rl-001"><span class="std std-ref">Howto RL-AGENT-001: Run an Agent with Own Policy</span></a></p></li>
</ul>
</div></blockquote>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="hyperopt.html" class="btn btn-neutral float-left" title="Hyperopt" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="openml.html" class="btn btn-neutral float-right" title="OpenML" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022 South Westphalia University of Applied Sciences, Germany.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>